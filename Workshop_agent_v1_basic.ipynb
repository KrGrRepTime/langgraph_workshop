{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "90ed3213",
   "metadata": {},
   "source": [
    "# LangGraph Agent v1 — Basic Q&A\n",
    "\n",
    "Single-node agent that answers directly with the LLM (no tools).\n",
    "\n",
    "Quick guide:\n",
    "- State: messages\n",
    "- Node: analyze (answer_question) → END\n",
    "- Observe prints: [ANSWER]\n",
    "- Run the last cell to see a clean, single execution trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8770e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import List, Optional, Union, Literal\n",
    "from dotenv import load_dotenv\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "# LangGraph\n",
    "from langgraph.graph import StateGraph, END\n",
    "\n",
    "# LangChain core\n",
    "from langchain_core.messages import HumanMessage, SystemMessage, AIMessage\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a745cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgentState(BaseModel):\n",
    "    messages: List[Union[HumanMessage, AIMessage, SystemMessage]] = Field(description=\"The chat history\")\n",
    "    class Config:\n",
    "        arbitrary_types_allowed = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e11c9fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize LLM\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-2.0-flash\", temperature=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "315a1acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer_question(state: AgentState):\n",
    "    print(\"[ANSWER] Executing answer_question node…\")\n",
    "\n",
    "    user_query = next((m.content for m in reversed(state.messages) if isinstance(m, HumanMessage)), \"\")\n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", \"You are a knowledgeable assistant. Today's date is 2025-08-27. Answer concisely and factually. If unsure or information is unavailable, say you don't know. Avoid speculation.\"),\n",
    "        (\"human\", \"Question: {q}\")\n",
    "    ])\n",
    "    ans = llm.invoke(prompt.format_messages(q=user_query)).content.strip()\n",
    "    return {\"messages\": [AIMessage(content=ans)]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "226c5c9b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63cb057a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build graph\n",
    "workflow_v1 = StateGraph(AgentState)\n",
    "workflow_v1.add_node(\"analyze\", answer_question)\n",
    "workflow_v1.add_edge(\"analyze\", END)\n",
    "\n",
    "workflow_v1.set_entry_point(\"analyze\")\n",
    "agent = workflow_v1.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8e48fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test v1\n",
    "query = \"Who won 2024 presidential elections in US?\"\n",
    "initial_state = AgentState(messages=[HumanMessage(content=query)])\n",
    "final_state = agent.invoke(initial_state)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7381be97",
   "metadata": {},
   "outputs": [],
   "source": [
    "for m in final_state['messages']:\n",
    "    if isinstance(m, HumanMessage):\n",
    "        print(f\"Human: {m.content}\")\n",
    "    elif isinstance(m, AIMessage):\n",
    "        print(f\"AI: {m.content}\")\n",
    "    else:\n",
    "        print(m)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
