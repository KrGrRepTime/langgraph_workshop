{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "90ed3213",
   "metadata": {},
   "source": [
    "# LangGraph Agent v1 — Basic Q&A\n",
    "\n",
    "Single-node agent that answers directly with the LLM (no tools).\n",
    "\n",
    "Quick guide:\n",
    "- State: messages\n",
    "- Node: analyze (answer_question) → END\n",
    "- Observe prints: [ANSWER]\n",
    "- Run the last cell to see a clean, single execution trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a8770e87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from typing import List, Optional, Union, Literal\n",
    "from dotenv import load_dotenv\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "# LangGraph\n",
    "from langgraph.graph import StateGraph, END\n",
    "\n",
    "# LangChain core\n",
    "from langchain_core.messages import HumanMessage, SystemMessage, AIMessage\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "8a745cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SearchResult(BaseModel):\n",
    "    id: int\n",
    "    title: str\n",
    "    snippet: str\n",
    "    link: str\n",
    "    relevance_score: Optional[float] = None\n",
    "    full_content: Optional[str] = None\n",
    "\n",
    "class AgentState(BaseModel):\n",
    "    messages: List[Union[HumanMessage, AIMessage, SystemMessage]] = Field(description=\"The chat history\")\n",
    "    class Config:\n",
    "        arbitrary_types_allowed = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e11c9fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize LLM\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-2.0-flash\", temperature=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "315a1acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer_question(state: AgentState):\n",
    "    print(\"[ANSWER] Executing answer_question node…\")\n",
    "    user_query = next((m.content for m in reversed(state.messages) if isinstance(m, HumanMessage)), \"\")\n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", \"You are a knowledgeable assistant. Be concise and factual.\"),\n",
    "        (\"human\", \"Answer: {q}\")\n",
    "    ])\n",
    "    ans = llm.invoke(prompt.format_messages(q=user_query)).content.strip()\n",
    "    return {\"messages\": [AIMessage(content=ans)]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "226c5c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_done(state: AgentState) -> Literal[\"end\"]:\n",
    "    return \"end\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "63cb057a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build graph\n",
    "workflow_v1 = StateGraph(AgentState)\n",
    "workflow_v1.add_node(\"analyze\", answer_question)\n",
    "workflow_v1.add_conditional_edges(\"analyze\", is_done, {\"end\": END})\n",
    "workflow_v1.set_entry_point(\"analyze\")\n",
    "agent = workflow_v1.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8e48fdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ANSWER] Executing answer_question node…\n",
      "==== Execution Trace ====\n",
      "(Watch for: [ANSWER])\n",
      "\n",
      "==== Conversation ====\n",
      "AI: As of October 2024, the teams that will be in the 2025 NBA playoffs are unknown. The playoffs occur at the end of the NBA season, and team qualification depends on their performance during the regular season.\n",
      "==== Execution Trace ====\n",
      "(Watch for: [ANSWER])\n",
      "\n",
      "==== Conversation ====\n",
      "AI: As of October 2024, the teams that will be in the 2025 NBA playoffs are unknown. The playoffs occur at the end of the NBA season, and team qualification depends on their performance during the regular season.\n"
     ]
    }
   ],
   "source": [
    "# Test v1\n",
    "query = \"What teams were in NBA playoffs in 2025?\"\n",
    "initial_state = AgentState(messages=[HumanMessage(content=query)])\n",
    "final_state = agent.invoke(initial_state)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7381be97",
   "metadata": {},
   "outputs": [],
   "source": [
    "for m in final_state['messages']:\n",
    "    if isinstance(m, HumanMessage):\n",
    "        print(f\"Human: {m.content}\")\n",
    "    elif isinstance(m, AIMessage):\n",
    "        print(f\"AI: {m.content}\")\n",
    "    else:\n",
    "        print(m)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
