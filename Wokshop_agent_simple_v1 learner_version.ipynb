{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad0db5ea",
   "metadata": {},
   "source": [
    "# Building AI Agents with LangGraph and LLMs\n",
    "\n",
    "This workshop guides you through creating an AI agent using LangGraph, a powerful framework for building stateful, reasoning-focused AI systems with explicit control flows.\n",
    "\n",
    "## What are AI Agents?\n",
    "\n",
    "AI agents are autonomous systems that perceive their environment, make decisions, and take actions to accomplish specific goals. Unlike simple language models that just respond to prompts, agents can:\n",
    "\n",
    "1. **Plan and Reason**: Break down complex tasks into logical steps\n",
    "2. **Use Tools**: Access external capabilities like search engines, databases, or APIs\n",
    "3. **Maintain State**: Remember context and previous actions across interactions\n",
    "4. **Make Decisions**: Choose appropriate actions based on their reasoning\n",
    "\n",
    "## What is LangGraph?\n",
    "\n",
    "LangGraph is a framework for building stateful, reasoning-focused AI systems with explicit control flows. It provides:\n",
    "\n",
    "1. **Structured Reasoning**: Create explicit multi-step reasoning processes\n",
    "2. **State Management**: Maintain and transform context between steps\n",
    "3. **Directed Workflows**: Design clear execution paths between components\n",
    "4. **Conditional Logic**: Implement decision-making capabilities\n",
    "\n",
    "In this workshop, we'll build a web search agent to demonstrate these concepts in action."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d96009e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import TypedDict, List, Annotated, Literal\n",
    "from dotenv import load_dotenv\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import List, Literal, Optional, Union\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "import json\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# LangGraph imports\n",
    "from langgraph.graph import StateGraph, END\n",
    "\n",
    "# LangChain imports\n",
    "from langchain_core.messages import HumanMessage, SystemMessage, AIMessage\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI  # Import Gemini\n",
    "from langchain_openai import ChatOpenAI  # Alternative: OpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "# For web search\n",
    "from langchain_community.utilities import GoogleSearchAPIWrapper  # Option 1\n",
    "from langchain_community.utilities import SerpAPIWrapper  # Option 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "281be10e",
   "metadata": {},
   "source": [
    "## Setting Up the Environment\n",
    "\n",
    "We'll start by importing the necessary libraries for our agent. These include:\n",
    "\n",
    "- **LangGraph**: For creating our agent's reasoning workflow\n",
    "- **LangChain**: For working with LLMs and tools\n",
    "- **Pydantic**: For creating strongly typed data models\n",
    "- **Web Search APIs**: To give our agent the ability to search the internet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5158692c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Google API key is set\n",
      "OpenAI API key is not set\n",
      "Google CSE ID is set\n",
      "SerpAPI key is not set\n"
     ]
    }
   ],
   "source": [
    "# Check if API keys are set\n",
    "print(\"Google API key is\", \"set\" if os.environ.get(\"GOOGLE_API_KEY\") else \"not set\")\n",
    "print(\"OpenAI API key is\", \"set\" if os.environ.get(\"OPENAI_API_KEY\") else \"not set\")\n",
    "print(\"Google CSE ID is\", \"set\" if os.environ.get(\"GOOGLE_CSE_ID\") else \"not set\")\n",
    "print(\"SerpAPI key is\", \"set\" if os.environ.get(\"SERPAPI_API_KEY\") else \"not set\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f683f782",
   "metadata": {},
   "source": [
    "## Checking API Keys\n",
    "\n",
    "Before proceeding, we need to verify that the necessary API keys are available in our environment:\n",
    "\n",
    "- **Google API Key**: For Gemini LLM access or Google search capabilities\n",
    "- **OpenAI API Key**: Alternative LLM provider\n",
    "- **Google CSE ID**: For Google Custom Search Engine\n",
    "- **SerpAPI Key**: Alternative search engine API\n",
    "\n",
    "The agent will use these APIs to access knowledge beyond its training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "203b285c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SearchResult(BaseModel):\n",
    "    id: int\n",
    "    title: str\n",
    "    snippet: str \n",
    "    link: str\n",
    "    relevance_score: Optional[float] = None\n",
    "    full_content: Optional[str] = None\n",
    "    \n",
    "class AgentState(BaseModel):\n",
    "    messages: List[Union[HumanMessage, AIMessage, SystemMessage]] = Field(description=\"The chat history\")\n",
    "    search_results: List[SearchResult] = Field(default_factory=list, description=\"The results from the web search\")\n",
    "    optimized_query: Optional[str] = Field(default=None, description=\"The LLM-optimized search query\")\n",
    "    \n",
    "    class Config:\n",
    "        arbitrary_types_allowed = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "68b5c684",
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer_question(state: AgentState):\n",
    "    user_query = next(\n",
    "        (m.content for m in reversed(state.messages)\n",
    "         if isinstance(m, HumanMessage)),\n",
    "        \"\"\n",
    "    )\n",
    "\n",
    "    answer_prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\",\n",
    "         \"You are a knowledgeable basketball analyst.\\n\"\n",
    "         \"• Always give concrete data you *know* (dates, scores, venues).\\n\"\n",
    "         \"• If you’re not sure of the newest result, cite the last result you’re sure about.\\n\"\n",
    "         \"• Include the actual score for any game you reference.\"),\n",
    "        (\"human\", \"Answer this as specifically as possible: {query}\")\n",
    "    ])\n",
    "\n",
    "    answer = llm.invoke(\n",
    "        answer_prompt.format_messages(query=user_query)\n",
    "    ).content.strip()\n",
    "\n",
    "    # Because messages has an `add_messages` reducer we can just\n",
    "    # return the *new* list element and LangGraph will append it.\n",
    "    return {\"messages\": [AIMessage(content=answer)]}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cba46817",
   "metadata": {},
   "source": [
    "## Basic Agent Implementation\n",
    "\n",
    "Here we implement our first agent function that analyzes user questions and provides responses.\n",
    "\n",
    "### Understanding Node Functions in LangGraph\n",
    "\n",
    "In LangGraph, **nodes** are functions that:\n",
    "1. Take the current state as input\n",
    "2. Perform some processing or reasoning\n",
    "3. Return a modified state as output\n",
    "\n",
    "Our `analyze_question` function implements this pattern by:\n",
    "1. Extracting the user's message from the state\n",
    "2. Creating a prompt for the LLM to answer the question\n",
    "3. Invoking the LLM to generate a response\n",
    "4. Adding the response to the message history in the state\n",
    "5. Returning the updated state\n",
    "\n",
    "This simple approach handles basic questions but has limitations - the LLM can only answer based on its training data, without access to current information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b7912de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# INSTRUCTOR_COMPLETE_THIS_IN_WORKSHOP\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-2.0-flash\", temperature = 0.7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cc127c7",
   "metadata": {},
   "source": [
    "## Initializing the Language Model\n",
    "\n",
    "We'll use Google's Gemini model as our reasoning engine. LLMs in agent systems serve multiple roles:\n",
    "\n",
    "1. **Core Reasoning**: Analyzing problems and planning solutions\n",
    "2. **Tool Use**: Deciding when and how to use available tools\n",
    "3. **Information Processing**: Extracting and synthesizing knowledge\n",
    "4. **Response Generation**: Creating human-readable outputs\n",
    "\n",
    "The choice of LLM impacts the agent's capabilities, with factors like context window size, reasoning abilities, and tool use proficiency all playing important roles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "73276d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_done(state: AgentState) -> Literal[\"end\"]:\n",
    "    \"\"\"Simple function to signal the end of the workflow\"\"\"\n",
    "    return \"end\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "364f8289",
   "metadata": {},
   "source": [
    "## Workflow Control Functions\n",
    "\n",
    "LangGraph uses specialized functions to control the flow of execution through the agent graph.\n",
    "\n",
    "Here we define `is_done`, a simple function that always returns \"end\" to signal that processing is complete and the workflow should terminate. In more complex agents, this function could implement conditional logic to determine whether more processing is needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "48d0fcac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# INSTRUCTOR_COMPLETE_THIS_IN_WORKSHOP\n",
    "# Create the graph with our extended functions\n",
    "workflow_v1 = StateGraph(AgentState)\n",
    "\n",
    "# Add our nodes\n",
    "workflow_v1.add_node(\"analyze\", answer_question)  # New entry point\n",
    "\n",
    "# Connect process to end\n",
    "workflow_v1.add_conditional_edges(\n",
    "    \"analyze\",\n",
    "    is_done,\n",
    "    {\n",
    "        \"end\": END,  # Always end after processing\n",
    "        \"continue\": \"analyze\"\n",
    "    }\n",
    ")\n",
    "\n",
    "# Set the entry point to our new analysis node\n",
    "workflow_v1.set_entry_point(\"analyze\")\n",
    "\n",
    "# Compile the graph\n",
    "agent = workflow_v1.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04b7c92c",
   "metadata": {},
   "source": [
    "## Creating the Graph Structure\n",
    "\n",
    "Now we'll build our first graph structure using LangGraph's `StateGraph`. This creates the workflow that our agent will follow.\n",
    "\n",
    "### Key Components of StateGraph:\n",
    "\n",
    "1. **Nodes**: Functions that process the state (`analyze_question`)\n",
    "2. **Edges**: Connections between nodes, defining the flow of execution\n",
    "3. **Conditional Edges**: Paths that depend on the state or routing functions\n",
    "4. **Entry Point**: The starting node when the graph is executed\n",
    "\n",
    "When compiled, the graph becomes a runnable agent that can process user queries through the defined workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e02fcb6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What teams were in NBA playoffs in 2025?\"\n",
    "initial_state = AgentState(messages=[HumanMessage(content=query)])\n",
    "\n",
    "# Run the agent\n",
    "final_state = agent.invoke(initial_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "51509e3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI: I do not have access to real-time information, including future NBA playoff results. The 2025 NBA playoffs have not yet happened, so the teams that will be participating are not yet known. Once the 2024-2025 regular season concludes, the playoff teams will be determined based on their regular season records.\n",
      "\n",
      "To give you an idea of how the playoffs work, in the *2024* playoffs, these were the teams that made it:\n",
      "\n",
      "**Eastern Conference:**\n",
      "\n",
      "*   (1) Boston Celtics\n",
      "*   (2) New York Knicks\n",
      "*   (3) Milwaukee Bucks\n",
      "*   (4) Cleveland Cavaliers\n",
      "*   (5) Orlando Magic\n",
      "*   (6) Indiana Pacers\n",
      "*   (7) Philadelphia 76ers\n",
      "*   (8) Miami Heat\n",
      "\n",
      "**Western Conference:**\n",
      "\n",
      "*   (1) Oklahoma City Thunder\n",
      "*   (2) Denver Nuggets\n",
      "*   (3) Minnesota Timberwolves\n",
      "*   (4) Los Angeles Clippers\n",
      "*   (5) Dallas Mavericks\n",
      "*   (6) Phoenix Suns\n",
      "*   (7) Los Angeles Lakers\n",
      "*   (8) New Orleans Pelicans\n"
     ]
    }
   ],
   "source": [
    "# Display the conversation\n",
    "for message in final_state['messages']:\n",
    "    if isinstance(message, HumanMessage):\n",
    "        print(f\"Human: {message.content}\")\n",
    "    elif isinstance(message, AIMessage):\n",
    "        print(f\"AI: {message.content}\")\n",
    "    else:\n",
    "        print(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fdd2e828",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [AIMessage(content='I do not have access to real-time information, including future NBA playoff results. The 2025 NBA playoffs have not yet happened, so the teams that will be participating are not yet known. Once the 2024-2025 regular season concludes, the playoff teams will be determined based on their regular season records.\\n\\nTo give you an idea of how the playoffs work, in the *2024* playoffs, these were the teams that made it:\\n\\n**Eastern Conference:**\\n\\n*   (1) Boston Celtics\\n*   (2) New York Knicks\\n*   (3) Milwaukee Bucks\\n*   (4) Cleveland Cavaliers\\n*   (5) Orlando Magic\\n*   (6) Indiana Pacers\\n*   (7) Philadelphia 76ers\\n*   (8) Miami Heat\\n\\n**Western Conference:**\\n\\n*   (1) Oklahoma City Thunder\\n*   (2) Denver Nuggets\\n*   (3) Minnesota Timberwolves\\n*   (4) Los Angeles Clippers\\n*   (5) Dallas Mavericks\\n*   (6) Phoenix Suns\\n*   (7) Los Angeles Lakers\\n*   (8) New Orleans Pelicans', additional_kwargs={}, response_metadata={})],\n",
       " 'search_results': []}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4010a0d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_engine = GoogleSearchAPIWrapper()  # Get top 3 results\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Node 1 – optimise the user query\n",
    "# ------------------------------------------------------------\n",
    "def analyze_query(state: AgentState):\n",
    "    \"\"\"Analyse the user’s last message and produce an optimised search query.\"\"\"\n",
    "    user_query = next(\n",
    "        (m.content for m in reversed(state.messages)\n",
    "         if isinstance(m, HumanMessage)),\n",
    "        \"\"\n",
    "    )\n",
    "\n",
    "    optimisation_prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\",\n",
    "         \"You are an expert at optimising search queries … \"\n",
    "         \"Return ONLY the optimised query.\"),\n",
    "        (\"human\", \"Optimise this search query: {query}\")\n",
    "    ])\n",
    "\n",
    "    optimised = llm.invoke(\n",
    "        optimisation_prompt.format_messages(query=user_query)\n",
    "    ).content.strip()\n",
    "\n",
    "    # ✅ Return *only* the update\n",
    "    return {\"optimized_query\": optimised}\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Node 2 – perform the web search\n",
    "# ------------------------------------------------------------\n",
    "def perform_search(state: AgentState):\n",
    "    \"\"\"Run a web search based on the (possibly) optimised query.\"\"\"\n",
    "    search_query = (\n",
    "        state.optimized_query\n",
    "        or next(\n",
    "            (m.content for m in reversed(state.messages)\n",
    "             if isinstance(m, HumanMessage)),\n",
    "            \"\"\n",
    "        )\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        raw_results = search_engine.results(search_query, num_results=3)\n",
    "    except Exception as err:\n",
    "        print(f\"Search API error: {err}\")\n",
    "        raw_results = [{\n",
    "            \"title\": \"Search temporarily unavailable\",\n",
    "            \"snippet\": f\"Could not retrieve results for: {search_query}.\",\n",
    "            \"link\": \"https://example.com\"\n",
    "        }]\n",
    "\n",
    "    results = [\n",
    "        SearchResult(\n",
    "            id=i + 1,\n",
    "            title=r.get(\"title\", \"No title\"),\n",
    "            snippet=r.get(\"snippet\", r.get(\"description\", \"No content\")),\n",
    "            link=r.get(\"link\", r.get(\"url\", \"No link\")),\n",
    "        )\n",
    "        for i, r in enumerate(raw_results)\n",
    "    ]\n",
    "\n",
    "    # ✅ Return *only* the update (list reducer will concatenate)\n",
    "    return {\"search_results\": results}\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Node 3 – synthesise an answer from search results\n",
    "# ------------------------------------------------------------\n",
    "def process_results(state: AgentState):\n",
    "    \"\"\"Generate a final answer that cites the search results.\"\"\"\n",
    "    from datetime import datetime\n",
    "    today = datetime.now().strftime(\"%B %d, %Y\")\n",
    "\n",
    "    # Format results for the LLM\n",
    "    if not state.search_results:\n",
    "        results_block = (\n",
    "            \"No search results available. \"\n",
    "            \"The search API may be inaccessible.\"\n",
    "        )\n",
    "    else:\n",
    "        parts = []\n",
    "        for r in state.search_results:\n",
    "            parts.append(\n",
    "                f\"Result {r.id}:\\n\"\n",
    "                f\"Title: {r.title}\\n\"\n",
    "                f\"Snippet: {r.snippet}\\n\"\n",
    "                f\"Source: {r.link}\\n\"\n",
    "            )\n",
    "            if r.full_content:\n",
    "                parts.append(f\"Extracted content:\\n{r.full_content}\\n\")\n",
    "        results_block = \"\\n\".join(parts)\n",
    "\n",
    "    original_query = next(\n",
    "        (m.content for m in state.messages if isinstance(m, HumanMessage)),\n",
    "        \"Unknown query\"\n",
    "    )\n",
    "\n",
    "    synthesis_prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\",\n",
    "         f\"You are a basketball analyst. Today is {today}.\\n\"\n",
    "         \"Use the search results to answer precisely, citing dates, scores, etc.\"),\n",
    "        (\"human\",\n",
    "         \"User query: {original_query}\\n\\nSearch results:\\n{search_results}\")\n",
    "    ])\n",
    "\n",
    "    answer = llm.invoke(\n",
    "        synthesis_prompt.format_messages(\n",
    "            original_query=original_query,\n",
    "            search_results=results_block\n",
    "        )\n",
    "    ).content.strip()\n",
    "\n",
    "    # ✅ Return only the new message; add_messages reducer appends it\n",
    "    return {\"messages\": [AIMessage(content=answer)]}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7dcce9b",
   "metadata": {},
   "source": [
    "## Enhanced Agent with Web Search Capabilities\n",
    "\n",
    "To make our agent more powerful, let's add web search capabilities. This transforms it from a system limited by training data to one that can access current information.\n",
    "\n",
    "### Multi-Step Reasoning Architecture\n",
    "\n",
    "We'll implement a more sophisticated workflow with multiple specialized components:\n",
    "\n",
    "1. **Query Analysis**: Optimize the user's question for search effectiveness\n",
    "2. **Search Execution**: Retrieve relevant information from the web\n",
    "3. **Result Processing**: Synthesize information into a coherent response\n",
    "\n",
    "This demonstrates a key pattern in LangGraph: breaking complex tasks into focused subtasks with dedicated reasoning at each step. By specializing each component, we get better performance than trying to accomplish everything in a single prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09aa4a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# INSTRUCTOR_COMPLETE_THIS_IN_WORKSHOP\n",
    "def route_to_search(state: AgentState) -> Literal[\"search\"]:\n",
    "    \"\"\"Route to the search node after query analysis\"\"\"\n",
    "    return \"search\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d76ff43",
   "metadata": {},
   "source": [
    "## Routing Functions in LangGraph\n",
    "\n",
    "Routing functions determine the flow of execution through the graph. They analyze the current state and return a string identifier that specifies which node should be executed next.\n",
    "\n",
    "Here, `route_to_search` always returns \"search\" - creating a simple linear flow from analysis to search. In more complex agents, these functions could implement sophisticated decision logic based on the state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a528a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STUDENT_IMPLEMENTATION_SECTION_BEGIN\n",
    "# Create the graph with our extended functions\n",
    "workflow_v2 = StateGraph(AgentState)\n",
    "\n",
    "# Set the entry point to our new analysis node\n",
    "workflow_v2.set_entry_point(\"analyze\")\n",
    "\n",
    "workflow_v2.add_edge(\"search\", \"process\")\n",
    "\n",
    "\n",
    "# Compile the graph\n",
    "agent_v2 = workflow_v2.compile()\n",
    "# STUDENT_IMPLEMENTATION_SECTION_END"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b08b774",
   "metadata": {},
   "source": [
    "## Designing the Enhanced Agent Graph\n",
    "\n",
    "Let's create a more advanced agent graph with our multi-step workflow.\n",
    "\n",
    "### LangGraph Workflow Design\n",
    "\n",
    "When designing LangGraph workflows, consider these principles:\n",
    "\n",
    "1. **Single Responsibility**: Each node should perform a specific, focused task\n",
    "2. **State Transformation**: Nodes transform the state in predictable ways\n",
    "3. **Explicit Decision Points**: Use conditional edges to represent decision logic\n",
    "4. **Error Handling**: Account for failures and edge cases\n",
    "\n",
    "Our enhanced agent follows this pattern with explicit nodes for query analysis, search, and result processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "890e1e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Who were in 2025 NBA playoffs?\"\n",
    "initial_state = AgentState(messages=[HumanMessage(content=query)])\n",
    "\n",
    "# Run the agent\n",
    "final_state = agent_v2.invoke(initial_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4d80ac1",
   "metadata": {},
   "source": [
    "## Testing Our Enhanced Agent\n",
    "\n",
    "Let's test our search-enabled agent with a specific query. The execution will follow these steps:\n",
    "\n",
    "1. Initial state with user query is created\n",
    "2. Query analysis optimizes the search terms\n",
    "3. Search retrieves relevant information\n",
    "4. Processing synthesizes a comprehensive response\n",
    "\n",
    "This demonstrates the multi-step reasoning pattern in action."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fda4b8a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell shows the full state object - you can run it to explore the complete state\n",
    "# final_state    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75770e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the conversation\n",
    "for message in final_state['messages']:\n",
    "    if isinstance(message, HumanMessage):\n",
    "        print(f\"Human: {message.content}\")\n",
    "    elif isinstance(message, AIMessage):\n",
    "        print(f\"AI: {message.content}\")\n",
    "    else:\n",
    "        print(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bd0e04e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "search_engine = GoogleSearchAPIWrapper(k=3)\n",
    "\n",
    "# ── Node 1 ────────────────────────────────────────────────────────────────────\n",
    "def analyze_query(state: AgentState):\n",
    "    \"\"\"Optimise the user’s last message into a tighter search query.\"\"\"\n",
    "    user_query = next(\n",
    "        (m.content for m in reversed(state.messages)\n",
    "         if isinstance(m, HumanMessage)), \"\"\n",
    "    )\n",
    "\n",
    "    today = datetime.now().strftime(\"%B %d, %Y\")\n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\",\n",
    "         f\"You are an expert at optimising search queries.\\nToday is {today}. \"\n",
    "         \"Return ONLY the optimised query, no explanation.\"),\n",
    "        (\"human\", \"Optimise this search query: {query}\")\n",
    "    ])\n",
    "\n",
    "    optimised = llm.invoke(\n",
    "        prompt.format_messages(query=user_query)\n",
    "    ).content.strip().replace('\"', '')\n",
    "\n",
    "    return {\"optimized_query\": optimised}\n",
    "\n",
    "\n",
    "# ── Utility (kept as is) ──────────────────────────────────────────────────────\n",
    "def fetch_full_content(url: str, max_length: int = 8_000) -> str:\n",
    "    \"\"\"Fetch full page text with basic error handling.\"\"\"\n",
    "    try:\n",
    "        loader = WebBaseLoader(\n",
    "            web_paths=[url],\n",
    "            header_template={\"User-Agent\":\n",
    "                \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) \"\n",
    "                \"AppleWebKit/537.36 (KHTML, like Gecko) \"\n",
    "                \"Chrome/120.0.0.0 Safari/537.36\"}\n",
    "        )\n",
    "        docs = loader.load()\n",
    "        if docs and docs[0].page_content.strip():\n",
    "            text = docs[0].page_content\n",
    "            return text[:max_length] + (\"…\" if len(text) > max_length else \"\")\n",
    "        return \"[Full content unavailable. Using search-result snippet instead]\"\n",
    "    except Exception as e:\n",
    "        if \"timeout\" in str(e).lower():\n",
    "            return \"[Content unavailable: Connection timed out]\"\n",
    "        if \"403\" in str(e) or \"forbidden\" in str(e).lower():\n",
    "            return \"[Content unavailable: Access forbidden]\"\n",
    "        if \"404\" in str(e) or \"not found\" in str(e).lower():\n",
    "            return \"[Content unavailable: Page not found]\"\n",
    "        return f\"[Content unavailable: {e}]\"\n",
    "\n",
    "\n",
    "# ── Node 2 ────────────────────────────────────────────────────────────────────\n",
    "def perform_search(state: AgentState):\n",
    "    \"\"\"Run Google search with the (maybe) optimised query.\"\"\"\n",
    "    query = state.optimized_query or next(\n",
    "        (m.content for m in reversed(state.messages)\n",
    "         if isinstance(m, HumanMessage)), \"\"\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        raw = search_engine.results(query, num_results=5)\n",
    "    except Exception as err:\n",
    "        print(f\"Search API error: {err}\")\n",
    "        raw = [{\n",
    "            \"title\": \"Search temporarily unavailable\",\n",
    "            \"snippet\": f\"Could not retrieve results for: {query}\",\n",
    "            \"link\": \"https://example.com\"\n",
    "        }]\n",
    "\n",
    "    results = [\n",
    "        SearchResult(\n",
    "            id=i + 1,\n",
    "            title=r.get(\"title\", \"No title\"),\n",
    "            snippet=r.get(\"snippet\", r.get(\"description\", \"No content\")),\n",
    "            link=r.get(\"link\", r.get(\"url\", \"No link\"))\n",
    "        )\n",
    "        for i, r in enumerate(raw)\n",
    "    ]\n",
    "\n",
    "    # list-reducer (`operator.add`) concatenates with existing results\n",
    "    return {\"search_results\": results}\n",
    "\n",
    "\n",
    "# ── Node 3 ────────────────────────────────────────────────────────────────────\n",
    "def enrich_content(state: AgentState):\n",
    "    \"\"\"Fetch each top result and let the LLM extract a concise summary.\"\"\"\n",
    "    if not state.search_results:\n",
    "        return {}        # nothing to do\n",
    "\n",
    "    user_query = next(\n",
    "        (m.content for m in state.messages if isinstance(m, HumanMessage)),\n",
    "        \"Unknown query\"\n",
    "    )\n",
    "\n",
    "    enriched = []\n",
    "    for result in state.search_results[:2]:      # enrich top 2\n",
    "        raw = fetch_full_content(result.link)\n",
    "        if raw.startswith(\"[Content unavailable\"):\n",
    "            result.full_content = raw\n",
    "        else:\n",
    "            ext_prompt = ChatPromptTemplate.from_messages([\n",
    "                (\"system\",\n",
    "                 \"Extract the information most relevant to the user’s query \"\n",
    "                 \"and summarise in ≤800 words.\"),\n",
    "                (\"human\",\n",
    "                 \"User query: {query}\\n\\nTitle: {title}\\nURL: {url}\\n\\nContent:\\n{content}\")\n",
    "            ])\n",
    "            summary = llm.invoke(\n",
    "                ext_prompt.format_messages(\n",
    "                    query=user_query,\n",
    "                    title=result.title,\n",
    "                    url=result.link,\n",
    "                    content=raw\n",
    "                )\n",
    "            ).content.strip()\n",
    "            result.full_content = summary\n",
    "        enriched.append(result)\n",
    "\n",
    "    # replace the first N results with their enriched versions\n",
    "    merged = enriched + state.search_results[len(enriched):]\n",
    "    return {\"search_results\": merged}\n",
    "\n",
    "\n",
    "# ── Node 4 ────────────────────────────────────────────────────────────────────\n",
    "def process_results(state: AgentState):\n",
    "    \"\"\"Synthesize a final answer citing the enriched search results.\"\"\"\n",
    "    today = datetime.now().strftime(\"%B %d, %Y\")\n",
    "    user_query = next(\n",
    "        (m.content for m in state.messages if isinstance(m, HumanMessage)),\n",
    "        \"Unknown query\"\n",
    "    )\n",
    "\n",
    "    if state.search_results:\n",
    "        blocks = []\n",
    "        for r in state.search_results:\n",
    "            blocks.append(\n",
    "                f\"Result {r.id} | {r.title}\\n\"\n",
    "                f\"{r.snippet}\\nSource: {r.link}\\n\"\n",
    "                f\"{r.full_content or ''}\\n\"\n",
    "            )\n",
    "        results_block = \"\\n\".join(blocks)\n",
    "    else:\n",
    "        results_block = (\n",
    "            \"No search results available – the search API may be down.\"\n",
    "        )\n",
    "\n",
    "    synth_prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\",\n",
    "         f\"You are a research assistant. Today is {today}. \"\n",
    "         \"Write a thorough, well-structured answer that cites dates, facts \"\n",
    "         \"and includes source attributions.\"),\n",
    "        (\"human\",\n",
    "         \"User query: {query}\\n\\nSearch results:\\n{results}\")\n",
    "    ])\n",
    "\n",
    "    answer = llm.invoke(\n",
    "        synth_prompt.format_messages(\n",
    "            query=user_query,\n",
    "            results=results_block\n",
    "        )\n",
    "    ).content.strip()\n",
    "\n",
    "    # add_messages reducer appends safely\n",
    "    return {\"messages\": [AIMessage(content=answer)]}\n",
    "# STUDENT_IMPLEMENTATION_SECTION_END"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "620d0ee4",
   "metadata": {},
   "source": [
    "## Advanced Agent with Content Enrichment\n",
    "\n",
    "### LLMs as Multi-Purpose Components\n",
    "\n",
    "In modern agent architecture, LLMs serve multiple roles beyond final output generation. Our agent demonstrates this with multiple LLM-powered processes:\n",
    "\n",
    "1. **Query Analysis and Optimization**: Before searching, the LLM analyzes the user's question to create more effective search terms.\n",
    "\n",
    "2. **Content Enrichment**: After retrieving search results, the LLM processes web content to extract the most relevant information.\n",
    "\n",
    "3. **Response Synthesis**: Finally, the LLM combines all information into a coherent, comprehensive answer.\n",
    "\n",
    "This multi-stage approach is far more effective than attempting to accomplish everything in a single LLM call. The `fetch_full_content` function enables a key capability: retrieving detailed information from web pages to augment the limited snippets provided by search engines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87332d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# INSTRUCTOR_COMPLETE_THIS_IN_WORKSHOP\n",
    "def route_to_search(state: AgentState) -> Literal[\"search\"]:\n",
    "    \"\"\"Route to the search node after query analysis\"\"\"\n",
    "    return \"search\"\n",
    "\n",
    "def should_enrich_content(state: AgentState) -> Literal[\"enrich\", \"process\"]:\n",
    "    \"\"\"Decide whether to enrich content or proceed to processing\"\"\"\n",
    "    # For simplicity in this workshop, we'll always enrich content\n",
    "    return \"enrich\"\n",
    "\n",
    "def is_done(state: AgentState) -> Literal[\"end\"]:\n",
    "    \"\"\"Simple function to signal the end of the workflow\"\"\"\n",
    "    return \"end\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "852e1769",
   "metadata": {},
   "source": [
    "## Dynamic Flow Control in LangGraph\n",
    "\n",
    "These functions control the flow of execution in our agent graph:\n",
    "\n",
    "1. **route_to_search**: Directs the flow from query analysis to search\n",
    "2. **should_enrich_content**: Determines whether to enrich content or proceed directly to processing\n",
    "3. **is_done**: Signals the end of the workflow\n",
    "\n",
    "Conditional routing enables dynamic decision-making in LangGraph. While our current functions are simple, they could implement complex logic in production systems, such as:\n",
    "\n",
    "- Skipping search for questions the LLM can answer directly\n",
    "- Enriching only the most promising search results\n",
    "- Triggering additional research for insufficient information\n",
    "\n",
    "These decision points are where the \"agent\" aspect truly emerges - the system adapts its behavior based on the specific context and needs of each query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92ab84df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STUDENT_IMPLEMENTATION_SECTION_BEGIN\n",
    "# Create the graph with our extended functions\n",
    "workflow = StateGraph(AgentState)\n",
    "\n",
    "\n",
    "# Compile the graph\n",
    "agent = workflow.compile()\n",
    "# STUDENT_IMPLEMENTATION_SECTION_END"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4729039",
   "metadata": {},
   "source": [
    "## Building the Complete Agent Workflow\n",
    "\n",
    "### LangGraph Architecture Patterns\n",
    "\n",
    "Our complete agent implementation demonstrates key LangGraph architecture patterns:\n",
    "\n",
    "1. **Graph-Based Orchestration**: Explicit workflow with clearly defined stages\n",
    "2. **Typed State Management**: Structured state passed and transformed between nodes\n",
    "3. **Conditional Branching**: Decision points that determine execution flow\n",
    "4. **Component Specialization**: Each node focused on a specific task\n",
    "\n",
    "The workflow follows this pattern:\n",
    "```\n",
    "[Analyze] → [Search] → [Enrich] → [Process] → END\n",
    "```\n",
    "\n",
    "This approach offers several advantages over monolithic agent designs:\n",
    "\n",
    "- **Maintainability**: Components can be improved independently\n",
    "- **Transparency**: Reasoning steps can be traced and debugged\n",
    "- **Specialization**: Prompts optimized for specific subtasks\n",
    "- **Robustness**: Failure in one component doesn't break the entire system\n",
    "\n",
    "These patterns are essential for building production-grade agent systems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f0b8ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize with a query about current NBA playoffs\n",
    "query = \"Who won US presidential election in 2024?\"\n",
    "initial_state = AgentState(messages=[HumanMessage(content=query)])\n",
    "\n",
    "# Run the agent\n",
    "final_state = agent.invoke(initial_state)\n",
    "\n",
    "# Display the conversation\n",
    "for message in final_state['messages']:\n",
    "    if isinstance(message, HumanMessage):\n",
    "        print(f\"Human: {message.content}\")\n",
    "    elif isinstance(message, AIMessage):\n",
    "        print(f\"AI: {message.content}\")\n",
    "    else:\n",
    "        print(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d699aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell shows the final state object - you can run it to explore the complete state\n",
    "# final_state"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7256c8f",
   "metadata": {},
   "source": [
    "## Putting It All Together: Testing the Complete Agent\n",
    "\n",
    "### The Complete Agent Experience\n",
    "\n",
    "Let's test our complete agent with a specific query. The execution will demonstrate the full workflow:\n",
    "\n",
    "1. **Query Analysis**: Optimizing the search terms\n",
    "2. **Search Execution**: Retrieving information from the web\n",
    "3. **Content Enrichment**: Processing detailed content from web pages\n",
    "4. **Response Synthesis**: Creating a comprehensive answer\n",
    "\n",
    "### Beyond This Workshop\n",
    "\n",
    "This workshop demonstrates fundamental patterns in LangGraph agent development, but many advanced capabilities are possible:\n",
    "\n",
    "1. **Memory and Long-term Context**: Storing and retrieving information across sessions\n",
    "2. **Multi-agent Systems**: Coordinating multiple specialized agents\n",
    "3. **Planning and Reflection**: Adding meta-cognitive abilities to agents\n",
    "4. **Feedback and Learning**: Improving agent performance over time\n",
    "5. **User Adaptation**: Customizing behavior based on user preferences\n",
    "\n",
    "By understanding the core concepts presented here, you're well-prepared to explore these more advanced topics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "224faacf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the final state\n",
    "final_state"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab52d3e8",
   "metadata": {},
   "source": [
    "## Workshop Summary and Key Takeaways\n",
    "\n",
    "### Core Concepts Covered\n",
    "\n",
    "1. **AI Agent Architecture**\n",
    "   - Components, state management, and decision making\n",
    "   - Structuring complex reasoning workflows\n",
    "\n",
    "2. **LangGraph Framework**\n",
    "   - StateGraph, nodes, edges, and conditional routing\n",
    "   - State transformation pattern\n",
    "\n",
    "3. **Multi-stage LLM Reasoning**\n",
    "   - Specialized prompting for subtasks\n",
    "   - Processing and synthesis patterns\n",
    "\n",
    "4. **Enhanced Agent Capabilities**\n",
    "   - Web search integration\n",
    "   - Content enrichment\n",
    "   - Response synthesis\n",
    "\n",
    "### Next Steps for Learning\n",
    "\n",
    "1. **Experiment with different LLMs** to compare their reasoning capabilities\n",
    "2. **Add more tools** to your agent (e.g., calculators, weather APIs)\n",
    "3. **Implement persistent memory** to maintain context across sessions\n",
    "4. **Create testing scenarios** to evaluate your agent's performance\n",
    "5. **Build domain-specific agents** for particular use cases\n",
    "\n",
    "By mastering these concepts, you're well on your way to developing sophisticated AI agents that can assist with complex, multi-step tasks while maintaining context and making intelligent decisions."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
