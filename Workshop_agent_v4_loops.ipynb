{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "928487b4",
   "metadata": {},
   "source": [
    "# üîÑ LangGraph Workshop: Mastering Loops & Cycles\n",
    "\n",
    "Welcome! In this hands-on workshop, you'll learn the **most important pattern** in production AI agents: **loops**.\n",
    "\n",
    "## Why Loops Matter\n",
    "\n",
    "Think about how you solve complex problems:\n",
    "- You don't get the perfect answer on the first try\n",
    "- You review, critique, and improve your work\n",
    "- You gather information from multiple sources\n",
    "- You iterate until you're satisfied\n",
    "\n",
    "**Agents should work the same way!**\n",
    "\n",
    "### The Problem with Linear Workflows\n",
    "\n",
    "Most tutorials show you this:\n",
    "```\n",
    "User Question ‚Üí LLM ‚Üí Answer ‚Üí Done\n",
    "```\n",
    "\n",
    "But real-world agents need to:\n",
    "- üîÑ **Self-improve**: Generate ‚Üí Critique ‚Üí Refine ‚Üí Repeat\n",
    "- \udd0d **Research deeply**: Plan ‚Üí Search ‚Üí Evaluate ‚Üí Search more\n",
    "- ü§ù **Collaborate**: Agent A ‚Üí Agent B ‚Üí Discuss ‚Üí Converge\n",
    "- üéØ **Meet quality standards**: Keep trying until good enough\n",
    "\n",
    "### What You'll Build Today\n",
    "\n",
    "By the end of this workshop, you'll have built **5 different loop patterns** from scratch, understanding when and how to use each one.\n",
    "\n",
    "**Let's transform your agents from one-shot wonders to resilient, self-improving systems!** üöÄ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acc325a7",
   "metadata": {},
   "source": [
    "## üéØ Learning Objectives\n",
    "\n",
    "By the end of this workshop, you will be able to:\n",
    "\n",
    "### 1Ô∏è‚É£ Understand Loop Fundamentals\n",
    "- **Create cycles** in your LangGraph by routing edges back to previous nodes\n",
    "- **Design exit conditions** that prevent infinite loops (safety first!)\n",
    "- **Track state evolution** across multiple iterations\n",
    "\n",
    "### 2Ô∏è‚É£ Implement 5 Loop Patterns\n",
    "\n",
    "You'll build working examples of:\n",
    "\n",
    "| Pattern | What You'll Learn | Difficulty |\n",
    "|---------|------------------|------------|\n",
    "| **Part 1: Fixed Iteration** | Loop exactly N times | ‚≠ê Beginner |\n",
    "| **Part 2: Quality-Driven** | Loop until quality threshold met (with scoring!) | ‚≠ê‚≠ê Intermediate |\n",
    "| **Part 3: Plan-Execution** | Loop through different searches (not same action!) | ‚≠ê‚≠ê Intermediate |\n",
    "| **Part 4: Streaming & Persistent** | Watch loops in real-time, resume later | ‚≠ê‚≠ê‚≠ê Advanced |\n",
    "| **Part 5: Multi-Agent Debate** | Two agents collaborate in a loop | ‚≠ê‚≠ê‚≠ê Advanced |\n",
    "\n",
    "### 3Ô∏è‚É£ Apply to Real Problems\n",
    "\n",
    "After each pattern, you'll understand:\n",
    "- ‚úÖ **When** to use this pattern\n",
    "- ‚úÖ **Why** it's better than alternatives\n",
    "- ‚úÖ **How** to adapt it to your use case\n",
    "- ‚ö†Ô∏è **Common pitfalls** to avoid\n",
    "\n",
    "### 4Ô∏è‚É£ Build Production-Ready Skills\n",
    "- Combine multiple loop patterns\n",
    "- Add safety limits and error handling\n",
    "- Monitor and debug loop behavior\n",
    "- Optimize for cost and latency\n",
    "\n",
    "---\n",
    "\n",
    "**Ready? Let's start with the simplest loop pattern!** üëá"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01690c76",
   "metadata": {},
   "source": [
    "## Setup & Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6224007",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "\n",
    "Before starting this workshop, ensure you have:\n",
    "\n",
    "1. **Python packages installed** (see `requirements.txt`):\n",
    "   ```bash\n",
    "   pip install langgraph langchain-google-genai langchain-community python-dotenv pydantic\n",
    "   ```\n",
    "\n",
    "2. **API Keys configured** in `.env` file:\n",
    "   ```\n",
    "   GOOGLE_API_KEY=your_gemini_api_key_here\n",
    "   GOOGLE_CSE_ID=your_custom_search_engine_id_here\n",
    "   ```\n",
    "\n",
    "3. **Basic LangGraph knowledge**: Understanding of StateGraph, nodes, edges, and state management\n",
    "\n",
    "**Note**: All examples use real LLM calls and APIs. No mock data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "503984e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core Python\n",
    "import os\n",
    "import sqlite3\n",
    "import atexit\n",
    "import time\n",
    "import re\n",
    "from pathlib import Path\n",
    "from typing import Annotated, Dict, List, Optional, Literal, Union\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "# LangGraph primitives\n",
    "from langgraph.graph import StateGraph, END, add_messages\n",
    "from langgraph.checkpoint.sqlite import SqliteSaver\n",
    "from langgraph.types import interrupt\n",
    "\n",
    "# LangChain\n",
    "from langchain_core.messages import HumanMessage, AIMessage, SystemMessage\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "load_dotenv()\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-2.0-flash\", temperature=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa8cae5d",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üîÅ Part 1: Your First Loop ‚Äî Fixed Iteration\n",
    "\n",
    "**Goal**: Build an agent that loops exactly 3 times, adding more detail with each pass.\n",
    "\n",
    "### The Challenge\n",
    "\n",
    "You ask: *\"What are LangGraph loops?\"*\n",
    "\n",
    "- **Iteration 1**: Brief 1-sentence answer\n",
    "- **Iteration 2**: Add 1-2 more sentences with details\n",
    "- **Iteration 3**: Expand even further\n",
    "\n",
    "**This is progressive elaboration** ‚Äî a common pattern in content generation!\n",
    "\n",
    "### What You'll Learn\n",
    "\n",
    "‚úÖ How to create a cycle by routing a conditional edge back to a node  \n",
    "‚úÖ How to track iterations with state  \n",
    "‚úÖ How to use a counter as an exit condition  \n",
    "\n",
    "**Let's build it!** üëá"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7246ac0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Simple loop agent compiled\n"
     ]
    }
   ],
   "source": [
    "class SimpleLoopState(BaseModel):\n",
    "    query: str = \"\"\n",
    "    answer: str = \"\"\n",
    "    iteration: int = 0\n",
    "    max_iterations: int = 3\n",
    "    \n",
    "    class Config:\n",
    "        arbitrary_types_allowed = True\n",
    "\n",
    "\n",
    "def improve_answer(state: SimpleLoopState):\n",
    "    \"\"\"Each iteration adds more detail to the answer.\"\"\"\n",
    "    iteration = state.iteration + 1\n",
    "    \n",
    "    if iteration == 1:\n",
    "        prompt = f\"Give a brief 1-sentence answer: {state.query}\"\n",
    "    else:\n",
    "        prompt = f\"Expand this answer with more detail:\\n\\nQuery: {state.query}\\nCurrent: {state.answer}\\n\\nAdd 1-2 more sentences.\"\n",
    "    \n",
    "    answer = llm.invoke(prompt).content\n",
    "    print(f\"\\n[Iteration {iteration}] Answer length: {len(answer)} chars\")\n",
    "    print(f\"Preview: {answer[:80]}...\")\n",
    "    \n",
    "    return {\"answer\": answer, \"iteration\": iteration}\n",
    "\n",
    "\n",
    "def should_continue_simple(state: SimpleLoopState) -> str:\n",
    "    \"\"\"Loop until max iterations reached.\"\"\"\n",
    "    if state.iteration < state.max_iterations:\n",
    "        print(f\"  ‚Üí Looping back (iteration {state.iteration}/{state.max_iterations})\")\n",
    "        return \"continue\"\n",
    "    else:\n",
    "        print(f\"  ‚Üí Done! Reached {state.max_iterations} iterations\")\n",
    "        return \"end\"\n",
    "\n",
    "\n",
    "# Build the loop\n",
    "simple_loop = StateGraph(SimpleLoopState)\n",
    "simple_loop.add_node(\"improve\", improve_answer)\n",
    "simple_loop.set_entry_point(\"improve\")\n",
    "\n",
    "# THE LOOP: conditional edge that can route back to \"improve\"\n",
    "simple_loop.add_conditional_edges(\n",
    "    \"improve\",\n",
    "    should_continue_simple,\n",
    "    {\n",
    "        \"continue\": \"improve\",  # üîÑ Loop back!\n",
    "        \"end\": END\n",
    "    }\n",
    ")\n",
    "\n",
    "simple_agent = simple_loop.compile()\n",
    "print(\"‚úÖ Simple loop agent compiled\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a65a63b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Iteration 1] Answer length: 164 chars\n",
      "Preview: LangGraph loops are a mechanism for creating stateful, cyclical workflows in Lan...\n",
      "  ‚Üí Looping back (iteration 1/3)\n",
      "\n",
      "[Iteration 2] Answer length: 411 chars\n",
      "Preview: LangGraph loops are a mechanism for creating stateful, cyclical workflows in Lan...\n",
      "  ‚Üí Looping back (iteration 2/3)\n",
      "\n",
      "[Iteration 2] Answer length: 411 chars\n",
      "Preview: LangGraph loops are a mechanism for creating stateful, cyclical workflows in Lan...\n",
      "  ‚Üí Looping back (iteration 2/3)\n",
      "\n",
      "[Iteration 3] Answer length: 734 chars\n",
      "Preview: LangGraph loops are a mechanism for creating stateful, cyclical workflows in Lan...\n",
      "  ‚Üí Done! Reached 3 iterations\n",
      "\n",
      "============================================================\n",
      "FINAL ANSWER:\n",
      "============================================================\n",
      "LangGraph loops are a mechanism for creating stateful, cyclical workflows in LangGraph, allowing agents to iterate and refine their actions based on previous steps. This enables more complex and dynamic interactions than linear chains, as the graph can return to previous nodes based on conditions or agent decisions. They are crucial for tasks requiring iterative problem-solving, planning, or self-correction. These loops are defined by conditional edges that determine the next node to visit based on the current state of the graph, effectively creating a feedback loop. This allows the LangGraph to dynamically adjust its execution path based on the outcomes of previous steps, leading to more robust and adaptable agent behavior.\n",
      "\n",
      "[Iteration 3] Answer length: 734 chars\n",
      "Preview: LangGraph loops are a mechanism for creating stateful, cyclical workflows in Lan...\n",
      "  ‚Üí Done! Reached 3 iterations\n",
      "\n",
      "============================================================\n",
      "FINAL ANSWER:\n",
      "============================================================\n",
      "LangGraph loops are a mechanism for creating stateful, cyclical workflows in LangGraph, allowing agents to iterate and refine their actions based on previous steps. This enables more complex and dynamic interactions than linear chains, as the graph can return to previous nodes based on conditions or agent decisions. They are crucial for tasks requiring iterative problem-solving, planning, or self-correction. These loops are defined by conditional edges that determine the next node to visit based on the current state of the graph, effectively creating a feedback loop. This allows the LangGraph to dynamically adjust its execution path based on the outcomes of previous steps, leading to more robust and adaptable agent behavior.\n"
     ]
    }
   ],
   "source": [
    "# Try it: Watch the agent loop 3 times\n",
    "result = simple_agent.invoke(SimpleLoopState(query=\"What are LangGraph loops?\"))\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"FINAL ANSWER:\")\n",
    "print(f\"{'='*60}\")\n",
    "print(result['answer'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba8e5bcc",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### ‚úÖ Part 1 Complete: Understanding Fixed-Iteration Loops\n",
    "\n",
    "**What You Just Built:**\n",
    "\n",
    "```mermaid\n",
    "graph LR\n",
    "    A[improve_answer] --> B{iteration < max?}\n",
    "    B -->|Yes: continue| A\n",
    "    B -->|No: end| C[END]\n",
    "```\n",
    "\n",
    "### üîë Key Concepts\n",
    "\n",
    "1. **The Loop Edge**: `\"continue\": \"improve\"` creates the cycle\n",
    "   ```python\n",
    "   simple_loop.add_conditional_edges(\n",
    "       \"improve\",\n",
    "       should_continue_simple,  # Routing function decides: loop or exit?\n",
    "       {\"continue\": \"improve\", \"end\": END}  # ‚Üê The magic happens here!\n",
    "   )\n",
    "   ```\n",
    "\n",
    "2. **State Tracking**: `iteration` counter increments each pass\n",
    "   - Iteration 1: Brief answer\n",
    "   - Iteration 2: Add details\n",
    "   - Iteration 3: Expand further ‚Üí **EXIT**\n",
    "\n",
    "3. **Exit Condition**: `iteration >= max_iterations` breaks the loop\n",
    "   - **Critical**: Without this, infinite loop! üî•\n",
    "   - Always have a safety limit!\n",
    "\n",
    "### üí° When to Use Fixed-Iteration Loops\n",
    "\n",
    "‚úÖ **Good for**:\n",
    "- **Ensembling**: Generate 5 candidates, pick best\n",
    "- **Progressive elaboration**: Build up answer iteratively (as shown)\n",
    "- **Multi-round reasoning**: Chain of Thought across N steps\n",
    "- **Predictable workflows**: When you know exactly how many passes you need\n",
    "\n",
    "‚ùå **Not good for**:\n",
    "- Quality-based work (you don't know how many tries it'll take)\n",
    "- Dynamic scenarios (where N isn't known upfront)\n",
    "\n",
    "### üéØ Try This!\n",
    "\n",
    "**Challenge**: Modify the code to loop 5 times instead of 3. Run it and see the answer grow!\n",
    "\n",
    "---\n",
    "\n",
    "**Next**: What if we don't know how many iterations we need? What if we want to loop **until quality is good enough**? Let's find out! üëâ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be11da30",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üìä Part 2: Quality-Driven Loop ‚Äî Self-Critique with Scoring\n",
    "\n",
    "**The Problem with Part 1**: What if your first answer is already perfect? Why waste 2 more LLM calls?\n",
    "\n",
    "**Better approach**: Loop **until quality threshold is met**!\n",
    "\n",
    "### The Challenge\n",
    "\n",
    "You ask: *\"Explain photosynthesis in mathematical terms\"*\n",
    "\n",
    "The agent should:\n",
    "1. **Generate** an answer\n",
    "2. **Score it** 0-100 based on 5 criteria\n",
    "3. **If score < 80**: Provide suggestions and regenerate\n",
    "4. **If score ‚â• 80**: Done! ‚úÖ\n",
    "\n",
    "Watch the score improve: 65 ‚Üí 78 ‚Üí 85 ‚Üí **Exit!**\n",
    "\n",
    "### What You'll Learn\n",
    "\n",
    "‚úÖ Quality-based exit conditions (not just counters)  \n",
    "‚úÖ Numeric scoring for measurable progress  \n",
    "‚úÖ Self-critique patterns (LLM evaluating itself)  \n",
    "‚úÖ Carrying feedback between iterations  \n",
    "\n",
    "**Let's build it!** üëá"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "475ad6ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Reflection agent compiled\n"
     ]
    }
   ],
   "source": [
    "class ReflectionState(BaseModel):\n",
    "    query: str = \"\"\n",
    "    draft: str = \"\"\n",
    "    critique_text: str = \"\"  # Renamed from 'critique' to avoid node name conflict\n",
    "    score: int = 0  # Score out of 100\n",
    "    iteration: int = 0\n",
    "    max_iterations: int = 5  # Reduced from 10 for learners\n",
    "    score_threshold: int = 80  # Quality threshold\n",
    "    \n",
    "    class Config:\n",
    "        arbitrary_types_allowed = True\n",
    "\n",
    "\n",
    "def generate_draft(state: ReflectionState):\n",
    "    \"\"\"Generate or refine based on critique.\"\"\"\n",
    "    iteration = state.iteration + 1\n",
    "    \n",
    "    if iteration == 1:\n",
    "        prompt = f\"Answer this query in 2-3 sentences: {state.query}\"\n",
    "    else:\n",
    "        prompt = f\"\"\"Query: {state.query}\n",
    "\n",
    "Previous answer (Score: {state.score}/100): {state.draft}\n",
    "\n",
    "Critique and suggestions: {state.critique_text}\n",
    "\n",
    "Rewrite the answer addressing ALL the suggestions. Make specific improvements mentioned.\"\"\"\n",
    "    \n",
    "    draft = llm.invoke(prompt).content\n",
    "    print(f\"\\n[GENERATE iteration {iteration}]\")\n",
    "    print(f\"  Draft: {draft[:1000]}...\")\n",
    "    \n",
    "    return {\"draft\": draft, \"iteration\": iteration}\n",
    "\n",
    "\n",
    "def critique_draft(state: ReflectionState):\n",
    "    \"\"\"Evaluate the draft quality with a score out of 100.\"\"\"\n",
    "    prompt = f\"\"\"Evaluate this answer and give it a score from 0-100.\n",
    "\n",
    "Query: {state.query}\n",
    "Answer: {state.draft}\n",
    "\n",
    "Scoring criteria:\n",
    "1. Directly addresses the query (20 points)\n",
    "2. Provides specific examples or evidence (20 points)\n",
    "3. Well-structured with clear logic (20 points)\n",
    "4. Uses concrete details, not vague generalities (20 points)\n",
    "5. Complete, covers all aspects (20 points)\n",
    "\n",
    "Format your response EXACTLY as:\n",
    "SCORE: [number from 0-100]\n",
    "REASONING: [brief explanation of the score]\n",
    "SUGGESTIONS: [2-3 specific improvements if score < 80, or \"None\" if score >= 80]\"\"\"\n",
    "    \n",
    "    critique_text = llm.invoke(prompt).content.strip()\n",
    "    \n",
    "    # Extract score from response\n",
    "    import re\n",
    "    score_match = re.search(r'SCORE:\\s*(\\d+)', critique_text)\n",
    "    score = int(score_match.group(1)) if score_match else 0\n",
    "    \n",
    "    print(f\"[CRITIQUE iteration {state.iteration}]\")\n",
    "    print(f\"  Score: {score}/100\")\n",
    "    if score >= state.score_threshold:\n",
    "        print(f\"  ‚úÖ Quality threshold met! (>= {state.score_threshold})\")\n",
    "    else:\n",
    "        print(f\"  ‚ùå Below threshold ({state.score_threshold}), needs improvement\")\n",
    "        # Extract suggestions\n",
    "        suggestions_match = re.search(r'SUGGESTIONS:\\s*(.+?)(?:\\n|$)', critique_text, re.DOTALL)\n",
    "        if suggestions_match:\n",
    "            suggestions = suggestions_match.group(1).strip()[:2000]\n",
    "            print(f\"  Suggestions: {suggestions}...\")\n",
    "    \n",
    "    return {\"critique_text\": critique_text, \"score\": score}\n",
    "\n",
    "\n",
    "def route_by_quality(state: ReflectionState) -> str:\n",
    "    \"\"\"Loop if score below threshold AND under max iterations.\"\"\"\n",
    "    if state.score >= state.score_threshold:\n",
    "        print(f\"  ‚Üí Finalizing (quality threshold met: {state.score}/{state.score_threshold})\")\n",
    "        return \"done\"\n",
    "    elif state.iteration >= state.max_iterations:\n",
    "        print(f\"  ‚Üí Finalizing (max iterations reached, final score: {state.score}/100)\")\n",
    "        return \"done\"\n",
    "    else:\n",
    "        print(f\"  ‚Üí Refining (attempt {state.iteration + 1}, current score: {state.score}/100)\")\n",
    "        return \"refine\"\n",
    "\n",
    "\n",
    "# Build reflection loop\n",
    "reflection_loop = StateGraph(ReflectionState)\n",
    "reflection_loop.add_node(\"generate\", generate_draft)  # Node name: \"generate\"\n",
    "reflection_loop.add_node(\"critique\", critique_draft)  # Node name: \"critique\" (no conflict now!)\n",
    "\n",
    "reflection_loop.set_entry_point(\"generate\")\n",
    "reflection_loop.add_edge(\"generate\", \"critique\")\n",
    "\n",
    "# THE LOOP: route back to generate if quality is insufficient\n",
    "reflection_loop.add_conditional_edges(\n",
    "    \"critique\",\n",
    "    route_by_quality,\n",
    "    {\n",
    "        \"refine\": \"generate\",  # üîÑ Loop back to improve\n",
    "        \"done\": END\n",
    "    }\n",
    ")\n",
    "\n",
    "reflection_agent = reflection_loop.compile()\n",
    "print(\"‚úÖ Reflection agent compiled\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b5d518a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[GENERATE iteration 1]\n",
      "  Draft: Assessing Trump's economic impact is complex and debated. Supporters point to tax cuts and deregulation as drivers of growth, while critics cite increased national debt and trade policies that harmed certain sectors. Overall, the economy saw growth during his presidency, but attributing this solely to his policies is difficult due to various global and pre-existing factors....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource exhausted. Please try again later. Please refer to https://cloud.google.com/vertex-ai/generative-ai/docs/error-code-429 for more details..\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CRITIQUE iteration 1]\n",
      "  Score: 75/100\n",
      "  ‚ùå Below threshold (80), needs improvement\n",
      "  Suggestions: 1. Mention specific examples of tax cuts (e.g., the Tax Cuts and Jobs Act of 2017) and deregulation policies....\n",
      "  ‚Üí Refining (attempt 2, current score: 75/100)\n",
      "\n",
      "[GENERATE iteration 2]\n",
      "  Draft: Okay, here's a revised answer incorporating the suggestions:\n",
      "\n",
      "**Revised Answer (Score: 90/100):**\n",
      "\n",
      "Assessing Trump's economic impact is complex and debated. Supporters point to the Tax Cuts and Jobs Act of 2017, which significantly lowered corporate and individual income tax rates, and deregulation efforts as drivers of economic growth. For example, there were efforts to roll back environmental regulations. Critics, however, cite a substantial increase in the national debt and trade policies that harmed certain sectors. During his presidency (2017-2021), the U.S. saw an average annual GDP growth rate of around 2.5%. However, the national debt increased significantly, rising from approximately $19.9 trillion to $27.8 trillion. While the economy experienced growth, attributing this solely to his policies is difficult. Global economic trends and pre-existing factors also played a role. For instance, his trade policies, particularly tariffs on goods from China, negatively impacted some U.S...\n",
      "[CRITIQUE iteration 2]\n",
      "  Score: 92/100\n",
      "  ‚úÖ Quality threshold met! (>= 80)\n",
      "  ‚Üí Finalizing (quality threshold met: 92/80)\n",
      "\n",
      "======================================================================\n",
      "FINAL ANSWER (after 2 iteration(s)):\n",
      "Final Score: 92/100\n",
      "======================================================================\n",
      "Okay, here's a revised answer incorporating the suggestions:\n",
      "\n",
      "**Revised Answer (Score: 90/100):**\n",
      "\n",
      "Assessing Trump's economic impact is complex and debated. Supporters point to the Tax Cuts and Jobs Act of 2017, which significantly lowered corporate and individual income tax rates, and deregulation efforts as drivers of economic growth. For example, there were efforts to roll back environmental regulations. Critics, however, cite a substantial increase in the national debt and trade policies that harmed certain sectors. During his presidency (2017-2021), the U.S. saw an average annual GDP growth rate of around 2.5%. However, the national debt increased significantly, rising from approximately $19.9 trillion to $27.8 trillion. While the economy experienced growth, attributing this solely to his policies is difficult. Global economic trends and pre-existing factors also played a role. For instance, his trade policies, particularly tariffs on goods from China, negatively impacted some U.S. manufacturers and consumers due to increased costs.\n"
     ]
    }
   ],
   "source": [
    "# Try it: Watch self-critique in action\n",
    "query = \"Is Trump good for economy?\"\n",
    "result = reflection_agent.invoke(ReflectionState(query=query))\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(f\"FINAL ANSWER (after {result['iteration']} iteration(s)):\")\n",
    "print(f\"Final Score: {result['score']}/100\")\n",
    "print(f\"{'='*70}\")\n",
    "print(result['draft'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e8c81c5",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### ‚úÖ Part 2 Complete: Quality-Driven Loops with Scoring\n",
    "\n",
    "**What You Just Built:**\n",
    "\n",
    "```mermaid\n",
    "graph LR\n",
    "    A[generate] --> B[critique + score]\n",
    "    B --> C{score >= 80?}\n",
    "    C -->|Yes| D[END]\n",
    "    C -->|No| A\n",
    "```\n",
    "\n",
    "### üîë Key Innovation: Measurable Quality\n",
    "\n",
    "Instead of vague \"is it good enough?\", we have **objective scoring**:\n",
    "\n",
    "```python\n",
    "# 5 criteria √ó 20 points each = 100\n",
    "1. Directly addresses query (20 pts)\n",
    "2. Specific examples/evidence (20 pts)  \n",
    "3. Well-structured logic (20 pts)\n",
    "4. Concrete details (20 pts)\n",
    "5. Complete coverage (20 pts)\n",
    "```\n",
    "\n",
    "**Why this is powerful:**\n",
    "- üìä **Trackable**: Watch score improve each iteration (65 ‚Üí 78 ‚Üí 85)\n",
    "- üéØ **Objective**: No ambiguity about \"good enough\"\n",
    "- üîß **Tunable**: Adjust threshold (70 for lenient, 90 for strict)\n",
    "- üêõ **Debuggable**: See exactly which criteria failed\n",
    "\n",
    "### üí° Exit Conditions: Two Ways Out\n",
    "\n",
    "```python\n",
    "if score >= 80:\n",
    "    return \"done\"  # ‚úÖ Quality met!\n",
    "elif iteration >= 5:\n",
    "    return \"done\"  # ‚ö†Ô∏è Max reached, accept what we have\n",
    "else:\n",
    "    return \"refine\"  # üîÑ Try again!\n",
    "```\n",
    "\n",
    "**Always have both**:\n",
    "1. ‚úÖ **Quality check** (desired exit)\n",
    "2. ‚ö†Ô∏è **Max iterations** (safety exit to prevent infinite loops)\n",
    "\n",
    "### üìà Real Output Example\n",
    "\n",
    "```\n",
    "[GENERATE iteration 1]\n",
    "  Draft: Photosynthesis converts light to energy...\n",
    "\n",
    "[CRITIQUE iteration 1]\n",
    "  Score: 65/100\n",
    "  ‚ùå Below threshold, needs improvement\n",
    "  Suggestions: Add equations, more specifics...\n",
    "\n",
    "[GENERATE iteration 2]  \n",
    "  Draft: Photosynthesis: 6CO‚ÇÇ + 6H‚ÇÇO + light ‚Üí C‚ÇÜH‚ÇÅ‚ÇÇO‚ÇÜ + 6O‚ÇÇ...\n",
    "\n",
    "[CRITIQUE iteration 2]\n",
    "  Score: 85/100\n",
    "  ‚úÖ Quality threshold met!\n",
    "\n",
    "FINAL ANSWER (after 2 iterations)\n",
    "```\n",
    "\n",
    "### üéØ When to Use Quality-Driven Loops\n",
    "\n",
    "‚úÖ **Perfect for**:\n",
    "- **Self-refinement**: Polish answers until good enough\n",
    "- **Code generation**: Compile ‚Üí Fix errors ‚Üí Repeat until works\n",
    "- **Content creation**: Draft ‚Üí Critique ‚Üí Improve\n",
    "- **Validation**: Check output meets standards\n",
    "\n",
    "‚ùå **Not ideal for**:\n",
    "- Tasks where quality is subjective\n",
    "- When you need deterministic iteration count\n",
    "- High-cost scenarios (could loop many times)\n",
    "\n",
    "### üß™ Experiments to Try\n",
    "\n",
    "1. **Adjust threshold**: Change `score_threshold` to 70 (easier) or 90 (stricter)\n",
    "2. **Modify criteria**: Add your own scoring criteria\n",
    "3. **Different queries**: Try questions that naturally score high vs. low\n",
    "\n",
    "---\n",
    "\n",
    "**Next**: We've looped over the *same* action (improve answer). But what if we need to loop through a *PLAN* of different actions? üëâ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7837d2bd",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üîç Part 3: Plan-Execution Loop ‚Äî Multi-Search Research\n",
    "\n",
    "**The Big Idea**: Parts 1 & 2 looped over the *same action*. Real agents need to loop through a *PLAN* of *different actions*!\n",
    "\n",
    "### The Challenge\n",
    "\n",
    "You ask: *\"What are the benefits and challenges of LangGraph?\"*\n",
    "\n",
    "A single search won't capture everything. Instead:\n",
    "1. **Plan**: Break into 3 focused searches:\n",
    "   - Search 1: \"LangGraph benefits production AI\"\n",
    "   - Search 2: \"LangGraph challenges limitations\"\n",
    "   - Search 3: \"LangGraph vs alternatives comparison\"\n",
    "2. **Execute loop**: Search 1 ‚Üí Search 2 ‚Üí Search 3\n",
    "3. **Synthesize**: Combine all results into comprehensive answer\n",
    "\n",
    "### Why This Pattern Matters\n",
    "\n",
    "üéØ **This is how real research agents work**:\n",
    "- Not just one search\n",
    "- Multiple perspectives\n",
    "- Comprehensive coverage\n",
    "\n",
    "### What You'll Learn\n",
    "\n",
    "‚úÖ Looping through a **list of different actions** (not same action)  \n",
    "‚úÖ Accumulating results across iterations  \n",
    "‚úÖ Early exit if sufficient coverage  \n",
    "‚úÖ Real API integration (Google Search)  \n",
    "\n",
    "### ‚öôÔ∏è Prerequisites\n",
    "\n",
    "This part uses **real Google Search API**. You'll need:\n",
    "- `GOOGLE_API_KEY` - [Get it here](https://developers.google.com/custom-search/v1/overview)\n",
    "- `GOOGLE_CSE_ID` - Custom Search Engine ID\n",
    "\n",
    "Add to your `.env` file!\n",
    "\n",
    "**Let's build a real research agent!** üëá"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b268df89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Research loop agent compiled\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.utilities import GoogleSearchAPIWrapper\n",
    "\n",
    "class ResearchLoopState(BaseModel):\n",
    "    query: str = \"\"\n",
    "    search_plan: List[str] = Field(default_factory=list)  # List of queries to execute\n",
    "    current_search_idx: int = 0\n",
    "    all_results: List[Dict] = Field(default_factory=list)  # Accumulated results\n",
    "    answer: str = \"\"\n",
    "    is_sufficient: bool = False\n",
    "    max_searches: int = 3\n",
    "    \n",
    "    class Config:\n",
    "        arbitrary_types_allowed = True\n",
    "\n",
    "\n",
    "def plan_searches(state: ResearchLoopState):\n",
    "    \"\"\"Create a plan of multiple search queries to gather comprehensive info.\"\"\"\n",
    "    prompt = f\"\"\"You are a research planner. Break this question into 2-3 focused search queries that cover different angles.\n",
    "\n",
    "Question: {state.query}\n",
    "\n",
    "For each query:\n",
    "- Focus on a specific aspect or perspective\n",
    "- Use effective search keywords\n",
    "- Avoid overlap between queries\n",
    "\n",
    "Return ONLY a numbered list of search queries (no explanations).\"\"\"\n",
    "    \n",
    "    plan_text = llm.invoke(prompt).content.strip()\n",
    "    \n",
    "    # Extract queries from numbered list\n",
    "    queries = re.findall(r'^\\d+\\.\\s*(.+)$', plan_text, re.MULTILINE)\n",
    "    queries = [q.strip().replace('\"', '') for q in queries[:3]]  # Max 3\n",
    "    \n",
    "    print(f\"\\n[PLAN] Created search plan with {len(queries)} queries:\")\n",
    "    for i, q in enumerate(queries, 1):\n",
    "        print(f\"  {i}. {q}\")\n",
    "    \n",
    "    return {\n",
    "        \"search_plan\": queries,\n",
    "        \"current_search_idx\": 0,\n",
    "        \"all_results\": []\n",
    "    }\n",
    "\n",
    "\n",
    "def execute_search(state: ResearchLoopState):\n",
    "    \"\"\"Execute the current search in the plan.\"\"\"\n",
    "    if state.current_search_idx >= len(state.search_plan):\n",
    "        print(f\"[SEARCH] No more searches in plan\")\n",
    "        return {}\n",
    "    \n",
    "    current_query = state.search_plan[state.current_search_idx]\n",
    "    search_num = state.current_search_idx + 1\n",
    "    \n",
    "    print(f\"\\n[SEARCH {search_num}/{len(state.search_plan)}] Query: {current_query}\")\n",
    "    \n",
    "    search_engine = GoogleSearchAPIWrapper()\n",
    "    raw_results = search_engine.results(current_query, num_results=3)\n",
    "    \n",
    "    # Extract and tag results with search context\n",
    "    results = [\n",
    "        {\n",
    "            \"search_query\": current_query,\n",
    "            \"search_num\": search_num,\n",
    "            \"title\": r.get(\"title\", \"No title\"),\n",
    "            \"snippet\": r.get(\"snippet\", r.get(\"description\", \"No snippet\")),\n",
    "            \"link\": r.get(\"link\", r.get(\"url\", \"\"))\n",
    "        }\n",
    "        for r in raw_results\n",
    "    ]\n",
    "    \n",
    "    print(f\"  ‚úÖ Found {len(results)} results\")\n",
    "    for i, r in enumerate(results, 1):\n",
    "        print(f\"    {i}. {r['title'][:50]}...\")\n",
    "    \n",
    "    # Accumulate results\n",
    "    all_results = state.all_results + results\n",
    "    next_idx = state.current_search_idx + 1\n",
    "    \n",
    "    return {\"all_results\": all_results, \"current_search_idx\": next_idx}\n",
    "\n",
    "\n",
    "def evaluate_coverage(state: ResearchLoopState):\n",
    "    \"\"\"Check if we have enough diverse information.\"\"\"\n",
    "    if not state.all_results:\n",
    "        print(f\"[EVALUATE] No results yet\")\n",
    "        return {\"is_sufficient\": False}\n",
    "    \n",
    "    # Format results grouped by search\n",
    "    results_by_search = {}\n",
    "    for r in state.all_results:\n",
    "        search_num = r['search_num']\n",
    "        if search_num not in results_by_search:\n",
    "            results_by_search[search_num] = []\n",
    "        results_by_search[search_num].append(r)\n",
    "    \n",
    "    summary = \"\\n\\n\".join([\n",
    "        f\"Search {num}: {results[0]['search_query']}\\n\" + \n",
    "        \"\\n\".join([f\"  - {r['title']}: {r['snippet'][:60]}...\" for r in results])\n",
    "        for num, results in sorted(results_by_search.items())\n",
    "    ])\n",
    "    \n",
    "    prompt = f\"\"\"Evaluate if these search results provide comprehensive coverage to answer the question.\n",
    "\n",
    "Question: {state.query}\n",
    "\n",
    "Results Summary:\n",
    "{summary}\n",
    "\n",
    "Total sources: {len(state.all_results)}\n",
    "Searches completed: {state.current_search_idx}/{len(state.search_plan)}\n",
    "\n",
    "Reply 'SUFFICIENT' if you have enough diverse information to provide a complete answer.\n",
    "Reply 'INSUFFICIENT' if more searches from the plan would help.\"\"\"\n",
    "    \n",
    "    evaluation = llm.invoke(prompt).content.strip()\n",
    "    is_sufficient = \"sufficient\" in evaluation.lower() and \"insufficient\" not in evaluation.lower()\n",
    "    \n",
    "    print(f\"\\n[EVALUATE] Coverage check:\")\n",
    "    print(f\"  Sources gathered: {len(state.all_results)}\")\n",
    "    print(f\"  Searches done: {state.current_search_idx}/{len(state.search_plan)}\")\n",
    "    \n",
    "    if is_sufficient:\n",
    "        print(f\"  ‚úÖ Coverage sufficient!\")\n",
    "    else:\n",
    "        print(f\"  ‚ùå Need more searches: {evaluation[:80]}...\")\n",
    "    \n",
    "    return {\"is_sufficient\": is_sufficient}\n",
    "\n",
    "\n",
    "def synthesize_research(state: ResearchLoopState):\n",
    "    \"\"\"Synthesize answer from all gathered results.\"\"\"\n",
    "    # Group by search for context\n",
    "    results_by_search = {}\n",
    "    for r in state.all_results:\n",
    "        search_num = r['search_num']\n",
    "        if search_num not in results_by_search:\n",
    "            results_by_search[search_num] = []\n",
    "        results_by_search[search_num].append(r)\n",
    "    \n",
    "    results_text = \"\\n\\n\".join([\n",
    "        f\"**Search {num}: {results[0]['search_query']}**\\n\" +\n",
    "        \"\\n\".join([f\"- {r['title']}\\n  {r['snippet']}\\n  Source: {r['link']}\" for r in results])\n",
    "        for num, results in sorted(results_by_search.items())\n",
    "    ])\n",
    "    \n",
    "    prompt = f\"\"\"Synthesize a comprehensive answer using ALL search results provided.\n",
    "\n",
    "Question: {state.query}\n",
    "\n",
    "Research Results:\n",
    "{results_text}\n",
    "\n",
    "Provide a complete answer that:\n",
    "1. Integrates information from multiple searches\n",
    "2. Cites sources with [source: URL]\n",
    "3. Acknowledges different perspectives if present\n",
    "4. Is well-structured and clear\"\"\"\n",
    "    \n",
    "    answer = llm.invoke(prompt).content\n",
    "    print(f\"\\n[SYNTHESIZE] Generated comprehensive answer ({len(answer)} chars)\")\n",
    "    \n",
    "    return {\"answer\": answer}\n",
    "\n",
    "\n",
    "def should_continue_searching(state: ResearchLoopState) -> str:\n",
    "    \"\"\"Loop through planned searches until sufficient coverage.\"\"\"\n",
    "    if state.is_sufficient:\n",
    "        print(f\"  ‚Üí Synthesizing (sufficient coverage)\")\n",
    "        return \"synthesize\"\n",
    "    elif state.current_search_idx >= len(state.search_plan):\n",
    "        print(f\"  ‚Üí Synthesizing (all planned searches done)\")\n",
    "        return \"synthesize\"\n",
    "    elif state.current_search_idx >= state.max_searches:\n",
    "        print(f\"  ‚Üí Synthesizing (max searches reached)\")\n",
    "        return \"synthesize\"\n",
    "    else:\n",
    "        remaining = len(state.search_plan) - state.current_search_idx\n",
    "        print(f\"  ‚Üí Continuing research ({remaining} search(es) remaining)\")\n",
    "        return \"continue\"\n",
    "\n",
    "\n",
    "# Build research loop\n",
    "research_loop = StateGraph(ResearchLoopState)\n",
    "research_loop.add_node(\"plan\", plan_searches)\n",
    "research_loop.add_node(\"search\", execute_search)\n",
    "research_loop.add_node(\"evaluate\", evaluate_coverage)\n",
    "research_loop.add_node(\"synthesize\", synthesize_research)\n",
    "\n",
    "research_loop.set_entry_point(\"plan\")\n",
    "research_loop.add_edge(\"plan\", \"search\")\n",
    "research_loop.add_edge(\"search\", \"evaluate\")\n",
    "\n",
    "# THE LOOP: continue executing searches from the plan\n",
    "research_loop.add_conditional_edges(\n",
    "    \"evaluate\",\n",
    "    should_continue_searching,\n",
    "    {\n",
    "        \"continue\": \"search\",      # üîÑ Loop back to next search\n",
    "        \"synthesize\": \"synthesize\"\n",
    "    }\n",
    ")\n",
    "\n",
    "research_loop.add_edge(\"synthesize\", END)\n",
    "\n",
    "research_agent = research_loop.compile()\n",
    "print(\"‚úÖ Research loop agent compiled\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d16ad390",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[PLAN] Created search plan with 3 queries:\n",
      "  1. LangGraph production deployment benefits challenges scalability\n",
      "  2. LangGraph agent orchestration real-world applications limitations\n",
      "  3. LangGraph state management complex workflows debugging monitoring\n",
      "\n",
      "[SEARCH 1/3] Query: LangGraph production deployment benefits challenges scalability\n",
      "  ‚úÖ Found 3 results\n",
      "    1. LangGraph in production? : r/LangChain...\n",
      "    2. LangGraph overview - Docs by LangChain...\n",
      "    3. LangGraph...\n",
      "  ‚úÖ Found 3 results\n",
      "    1. LangGraph in production? : r/LangChain...\n",
      "    2. LangGraph overview - Docs by LangChain...\n",
      "    3. LangGraph...\n",
      "\n",
      "[EVALUATE] Coverage check:\n",
      "  Sources gathered: 3\n",
      "  Searches done: 1/3\n",
      "  ‚ùå Need more searches: INSUFFICIENT...\n",
      "  ‚Üí Continuing research (2 search(es) remaining)\n",
      "\n",
      "[SEARCH 2/3] Query: LangGraph agent orchestration real-world applications limitations\n",
      "\n",
      "[EVALUATE] Coverage check:\n",
      "  Sources gathered: 3\n",
      "  Searches done: 1/3\n",
      "  ‚ùå Need more searches: INSUFFICIENT...\n",
      "  ‚Üí Continuing research (2 search(es) remaining)\n",
      "\n",
      "[SEARCH 2/3] Query: LangGraph agent orchestration real-world applications limitations\n",
      "  ‚úÖ Found 3 results\n",
      "    1. Can anyone explain the benefits and limitations of...\n",
      "    2. Comparing AI agent frameworks: CrewAI, LangGraph, ...\n",
      "    3. Building AI Workflows with LangGraph: Practical Us...\n",
      "  ‚úÖ Found 3 results\n",
      "    1. Can anyone explain the benefits and limitations of...\n",
      "    2. Comparing AI agent frameworks: CrewAI, LangGraph, ...\n",
      "    3. Building AI Workflows with LangGraph: Practical Us...\n",
      "\n",
      "[EVALUATE] Coverage check:\n",
      "  Sources gathered: 6\n",
      "  Searches done: 2/3\n",
      "  ‚ùå Need more searches: INSUFFICIENT...\n",
      "  ‚Üí Continuing research (1 search(es) remaining)\n",
      "\n",
      "[SEARCH 3/3] Query: LangGraph state management complex workflows debugging monitoring\n",
      "\n",
      "[EVALUATE] Coverage check:\n",
      "  Sources gathered: 6\n",
      "  Searches done: 2/3\n",
      "  ‚ùå Need more searches: INSUFFICIENT...\n",
      "  ‚Üí Continuing research (1 search(es) remaining)\n",
      "\n",
      "[SEARCH 3/3] Query: LangGraph state management complex workflows debugging monitoring\n",
      "  ‚úÖ Found 3 results\n",
      "    1. Spoke to 22 LangGraph devs and here's what we foun...\n",
      "    2. OpenAI Agents SDK vs LangGraph vs Autogen vs CrewA...\n",
      "    3. OpenAI's new framework for Agents. Why is Langgrap...\n",
      "  ‚úÖ Found 3 results\n",
      "    1. Spoke to 22 LangGraph devs and here's what we foun...\n",
      "    2. OpenAI Agents SDK vs LangGraph vs Autogen vs CrewA...\n",
      "    3. OpenAI's new framework for Agents. Why is Langgrap...\n",
      "\n",
      "[EVALUATE] Coverage check:\n",
      "  Sources gathered: 9\n",
      "  Searches done: 3/3\n",
      "  ‚úÖ Coverage sufficient!\n",
      "  ‚Üí Synthesizing (sufficient coverage)\n",
      "\n",
      "[EVALUATE] Coverage check:\n",
      "  Sources gathered: 9\n",
      "  Searches done: 3/3\n",
      "  ‚úÖ Coverage sufficient!\n",
      "  ‚Üí Synthesizing (sufficient coverage)\n",
      "\n",
      "[SYNTHESIZE] Generated comprehensive answer (3058 chars)\n",
      "\n",
      "======================================================================\n",
      "RESEARCH COMPLETE\n",
      "======================================================================\n",
      "\n",
      "Search plan executed:\n",
      "  1. LangGraph production deployment benefits challenges scalability\n",
      "  2. LangGraph agent orchestration real-world applications limitations\n",
      "  3. LangGraph state management complex workflows debugging monitoring\n",
      "\n",
      "Total sources gathered: 9\n",
      "\n",
      "======================================================================\n",
      "FINAL ANSWER:\n",
      "======================================================================\n",
      "\n",
      "LangGraph is a framework designed to build robust and scalable multi-agent systems, offering both benefits and challenges when used in production AI systems. It excels in agent orchestration and managing complex workflows, but also presents difficulties in areas like debugging and ease of setup.\n",
      "\n",
      "**Benefits of using LangGraph in Production:**\n",
      "\n",
      "*   **Durable Execution and Scalability:** LangGraph enables the creation of agents that persist and can be deployed confidently in production environments with scalable infrastructure. [source: https://docs.langchain.com/oss/python/langgraph/overview, https://langchain-ai.github.io/langgraph/]\n",
      "*   **Abstraction of Flow Logic:** It simplifies the implementation of complex workflows by abstracting the flow logic. [source: https://www.reddit.com/r/LangChain/comments/1eh0ly3/spoke-to-22-langgraph-devs-and-heres-what-we-found/]\n",
      "*   **Superior State Management:** LangGraph offers superior state management capabilities, which is crucial for complex, multi-agent workflows. [source: https://composio.dev/blog/openai-agents-sdk-vs-langgraph-vs-autogen-vs-crewai]\n",
      "*   **Integration with LangChain:** LangGraph integrates well with existing LangChain tools and components, leveraging the broader LangChain ecosystem. [source: https://www.reddit.com/r/LangChain/comments/1g1pkki/openais_new_framework_for_agents_why_is_langgraph/]\n",
      "*   **Real-World Applications:** LangGraph can be applied to solve various real-world problems across different industries through agent orchestration. [source: https://www.scalablepath.com/machine-learning/langgraph]\n",
      "*   **Autonomous Decision-Making:** Useful for real-time adaptability. [source: https://www.reddit.com/r/AI_Agents/comments/1hdv7vg/can-anyone-explain-the-benefits-and-limitations/]\n",
      "\n",
      "**Challenges of using LangGraph in Production:**\n",
      "\n",
      "*   **Debugging and Monitoring:**  While LangGraph aims to make debugging straightforward, some users have found it challenging, particularly in tracking state and understanding the flow of execution. [source: https://www.reddit.com/r/LangChain/comments/1eh0ly3/spoke-to-22-langgraph-devs-and-heres-what-we-found/, https://composio.dev/blog/openai-agents-sdk-vs-langgraph-vs-autogen-vs-crewai]\n",
      "*   **Setup Complexity:** Setting up and configuring LangGraph for production can be complex, as indicated by users experiencing difficulties. [source: https://www.reddit.com/r/LangChain/comments/1dl47vz/langgraph_in_production/]\n",
      "*   **Limited Tooling:** There may be a lack of readily available tools to facilitate easy setup and deployment. [source: https://www.reddit.com/r/LangChain/comments/1dl47vz/langgraph_in_production/]\n",
      "\n",
      "In summary, LangGraph provides a powerful framework for building sophisticated multi-agent systems with durable execution and scalable deployment. Its strengths lie in managing complex workflows and state. However, developers should be aware of the potential challenges related to debugging, setup complexity, and the need for robust monitoring strategies when deploying LangGraph in production environments.\n",
      "\n",
      "[SYNTHESIZE] Generated comprehensive answer (3058 chars)\n",
      "\n",
      "======================================================================\n",
      "RESEARCH COMPLETE\n",
      "======================================================================\n",
      "\n",
      "Search plan executed:\n",
      "  1. LangGraph production deployment benefits challenges scalability\n",
      "  2. LangGraph agent orchestration real-world applications limitations\n",
      "  3. LangGraph state management complex workflows debugging monitoring\n",
      "\n",
      "Total sources gathered: 9\n",
      "\n",
      "======================================================================\n",
      "FINAL ANSWER:\n",
      "======================================================================\n",
      "\n",
      "LangGraph is a framework designed to build robust and scalable multi-agent systems, offering both benefits and challenges when used in production AI systems. It excels in agent orchestration and managing complex workflows, but also presents difficulties in areas like debugging and ease of setup.\n",
      "\n",
      "**Benefits of using LangGraph in Production:**\n",
      "\n",
      "*   **Durable Execution and Scalability:** LangGraph enables the creation of agents that persist and can be deployed confidently in production environments with scalable infrastructure. [source: https://docs.langchain.com/oss/python/langgraph/overview, https://langchain-ai.github.io/langgraph/]\n",
      "*   **Abstraction of Flow Logic:** It simplifies the implementation of complex workflows by abstracting the flow logic. [source: https://www.reddit.com/r/LangChain/comments/1eh0ly3/spoke-to-22-langgraph-devs-and-heres-what-we-found/]\n",
      "*   **Superior State Management:** LangGraph offers superior state management capabilities, which is crucial for complex, multi-agent workflows. [source: https://composio.dev/blog/openai-agents-sdk-vs-langgraph-vs-autogen-vs-crewai]\n",
      "*   **Integration with LangChain:** LangGraph integrates well with existing LangChain tools and components, leveraging the broader LangChain ecosystem. [source: https://www.reddit.com/r/LangChain/comments/1g1pkki/openais_new_framework_for_agents_why_is_langgraph/]\n",
      "*   **Real-World Applications:** LangGraph can be applied to solve various real-world problems across different industries through agent orchestration. [source: https://www.scalablepath.com/machine-learning/langgraph]\n",
      "*   **Autonomous Decision-Making:** Useful for real-time adaptability. [source: https://www.reddit.com/r/AI_Agents/comments/1hdv7vg/can-anyone-explain-the-benefits-and-limitations/]\n",
      "\n",
      "**Challenges of using LangGraph in Production:**\n",
      "\n",
      "*   **Debugging and Monitoring:**  While LangGraph aims to make debugging straightforward, some users have found it challenging, particularly in tracking state and understanding the flow of execution. [source: https://www.reddit.com/r/LangChain/comments/1eh0ly3/spoke-to-22-langgraph-devs-and-heres-what-we-found/, https://composio.dev/blog/openai-agents-sdk-vs-langgraph-vs-autogen-vs-crewai]\n",
      "*   **Setup Complexity:** Setting up and configuring LangGraph for production can be complex, as indicated by users experiencing difficulties. [source: https://www.reddit.com/r/LangChain/comments/1dl47vz/langgraph_in_production/]\n",
      "*   **Limited Tooling:** There may be a lack of readily available tools to facilitate easy setup and deployment. [source: https://www.reddit.com/r/LangChain/comments/1dl47vz/langgraph_in_production/]\n",
      "\n",
      "In summary, LangGraph provides a powerful framework for building sophisticated multi-agent systems with durable execution and scalable deployment. Its strengths lie in managing complex workflows and state. However, developers should be aware of the potential challenges related to debugging, setup complexity, and the need for robust monitoring strategies when deploying LangGraph in production environments.\n"
     ]
    }
   ],
   "source": [
    "# Try it: Watch the agent execute multi-search research\n",
    "query = \"What are the benefits and challenges of using LangGraph for production AI systems?\"\n",
    "result = research_agent.invoke(ResearchLoopState(query=query))\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(f\"RESEARCH COMPLETE\")\n",
    "print(f\"{'='*70}\")\n",
    "print(f\"\\nSearch plan executed:\")\n",
    "for i, q in enumerate(result['search_plan'], 1):\n",
    "    print(f\"  {i}. {q}\")\n",
    "print(f\"\\nTotal sources gathered: {len(result['all_results'])}\")\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"FINAL ANSWER:\")\n",
    "print(f\"{'='*70}\")\n",
    "print(f\"\\n{result['answer']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "110246a8",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### ‚úÖ Part 3 Complete: Plan-Execution Loops\n",
    "\n",
    "**What You Just Built:**\n",
    "\n",
    "```mermaid\n",
    "graph LR\n",
    "    A[plan: create 3 queries] --> B[search query 1]\n",
    "    B --> C[evaluate coverage]\n",
    "    C -->|insufficient| D[search query 2]\n",
    "    D --> E[evaluate coverage]\n",
    "    E -->|insufficient| F[search query 3]\n",
    "    F --> G[evaluate coverage]\n",
    "    G -->|sufficient| H[synthesize answer]\n",
    "```\n",
    "\n",
    "### üîë Key Innovation: Different Actions Each Loop!\n",
    "\n",
    "**Parts 1 & 2**: Same action repeated\n",
    "```\n",
    "improve ‚Üí improve ‚Üí improve\n",
    "```\n",
    "\n",
    "**Part 3**: Plan executed sequentially\n",
    "```\n",
    "search \"benefits\" ‚Üí search \"challenges\" ‚Üí search \"comparison\"\n",
    "```\n",
    "\n",
    "### üéØ The Four Phases\n",
    "\n",
    "1. **PLAN Phase** (once)\n",
    "   - LLM breaks question into 2-3 search angles\n",
    "   - Stored in `search_plan` list\n",
    "\n",
    "2. **SEARCH Loop** (repeats)\n",
    "   - Execute `search_plan[current_search_idx]`\n",
    "   - Accumulate results\n",
    "   - Increment `current_search_idx`\n",
    "\n",
    "3. **EVALUATE** (after each search)\n",
    "   - Do we have enough information?\n",
    "   - Early exit if yes! (saves API calls)\n",
    "\n",
    "4. **SYNTHESIZE** (once at end)\n",
    "   - Combine all results\n",
    "   - Cite sources\n",
    "   - Produce final answer\n",
    "\n",
    "### üí° State Management Pattern\n",
    "\n",
    "```python\n",
    "class ResearchLoopState:\n",
    "    search_plan: List[str]         # [\"query1\", \"query2\", \"query3\"]\n",
    "    current_search_idx: int        # Which search are we on? (0, 1, 2)\n",
    "    all_results: List[Dict]        # Accumulated results from all searches\n",
    "    is_sufficient: bool            # Early exit flag\n",
    "```\n",
    "\n",
    "**Why this works**:\n",
    "- `search_plan` = **the roadmap**\n",
    "- `current_search_idx` = **where we are** on the roadmap\n",
    "- `all_results` = **what we've collected** so far\n",
    "\n",
    "### üöÄ Real-World Applications\n",
    "\n",
    "‚úÖ **Research agents**: Comprehensive information gathering  \n",
    "‚úÖ **Competitive analysis**: Search multiple competitors  \n",
    "‚úÖ **Due diligence**: Investigate different aspects  \n",
    "‚úÖ **Multi-source fact-checking**: Verify from different angles  \n",
    "‚úÖ **Market research**: Gather diverse perspectives  \n",
    "\n",
    "### üí∞ Why Early Exit Matters\n",
    "\n",
    "```python\n",
    "# Without early exit: Always 3 searches = 3 API calls\n",
    "search 1 ‚Üí search 2 ‚Üí search 3 ‚Üí synthesize\n",
    "\n",
    "# With early exit: Stop when sufficient\n",
    "search 1 ‚Üí search 2 ‚Üí sufficient! ‚Üí synthesize  (saved 1 call!)\n",
    "```\n",
    "\n",
    "**In production**: This saves money and latency!\n",
    "\n",
    "### üéì Progression So Far\n",
    "\n",
    "| Part | Loop Type | Exit Strategy |\n",
    "|------|-----------|---------------|\n",
    "| Part 1 | Fixed iteration | Counter (3 loops) |\n",
    "| Part 2 | Quality-driven | Score ‚â• 80 |\n",
    "| Part 3 | Plan-execution | Plan complete OR sufficient |\n",
    "\n",
    "**Pattern**: Each part builds on the previous! üéØ\n",
    "\n",
    "### üß™ Experiments to Try\n",
    "\n",
    "1. **Modify plan**: Change `plan_searches()` to create 4-5 queries instead of 2-3\n",
    "2. **Adjust threshold**: Make `evaluate_coverage()` more/less strict\n",
    "3. **Different domain**: Try medical research, legal research, technical docs\n",
    "\n",
    "---\n",
    "\n",
    "**Next**: Now that you master the core patterns, let's combine loops with advanced features like **streaming** and **persistence**! üëâ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1959613b",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üé¨ Part 4: Advanced Features ‚Äî Streaming & Persistent Loops\n",
    "\n",
    "**You've mastered loops! Now let's add production features.**\n",
    "\n",
    "### Feature 1: Streaming üî¥ LIVE\n",
    "\n",
    "**Problem**: Your quality loop runs 5 iterations. You wait... and wait... then finally see results.\n",
    "\n",
    "**Better**: Watch each iteration **in real-time** as it happens!\n",
    "\n",
    "```python\n",
    "for update in agent.stream(state):\n",
    "    print(f\"Iteration {update['iteration']}: Score {update['score']}/100\")\n",
    "```\n",
    "\n",
    "### Feature 2: Checkpointing üíæ\n",
    "\n",
    "**Problem**: Your research loop takes 3 minutes. Browser crashes. Start over. üò¢\n",
    "\n",
    "**Better**: Save state after each iteration. Resume right where you left off!\n",
    "\n",
    "```python\n",
    "# Run iteration 1-2\n",
    "agent.invoke(state, config={\"thread_id\": \"research_123\"})\n",
    "# Browser crashes...\n",
    "# Resume from iteration 3\n",
    "agent.invoke(state, config={\"thread_id\": \"research_123\"})  # Continues!\n",
    "```\n",
    "\n",
    "### What You'll Learn\n",
    "\n",
    "‚úÖ Real-time loop monitoring with `.stream()`  \n",
    "‚úÖ Persistent state with `SqliteSaver`  \n",
    "‚úÖ Thread-based conversations  \n",
    "‚úÖ Resume interrupted workflows  \n",
    "\n",
    "**Let's add these superpowers!** üëá"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d538d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup persistent checkpointer\n",
    "STATE_DIR = Path.cwd() / \"langgraph_state\"\n",
    "STATE_DIR.mkdir(parents=True, exist_ok=True)\n",
    "DB_PATH = STATE_DIR / \"workshop_v4_loops.db\"\n",
    "\n",
    "try:\n",
    "    conn = sqlite3.connect(str(DB_PATH), check_same_thread=False)\n",
    "    checkpointer = SqliteSaver(conn)\n",
    "    atexit.register(conn.close)\n",
    "    print(f\"‚úÖ Checkpointer ready at {DB_PATH}\")\n",
    "except Exception as exc:\n",
    "    conn = sqlite3.connect(\":memory:\", check_same_thread=False)\n",
    "    checkpointer = SqliteSaver(conn)\n",
    "    print(f\"‚ö†Ô∏è Using in-memory checkpointer\")\n",
    "\n",
    "# Compile reflection agent with persistence\n",
    "persistent_reflection = reflection_loop.compile(checkpointer=checkpointer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98aa2b18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stream_reflection(query: str, thread_id: str = \"default\"):\n",
    "    \"\"\"Stream each iteration of the reflection loop.\"\"\"\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"STREAMING REFLECTION LOOP: {query}\")\n",
    "    print(f\"{'='*70}\\n\")\n",
    "    \n",
    "    config = {\"configurable\": {\"thread_id\": thread_id}}\n",
    "    state = ReflectionState(query=query)\n",
    "    \n",
    "    for update in persistent_reflection.stream(state, config):\n",
    "        for node_name, delta in update.items():\n",
    "            print(f\"[STREAM] node={node_name:>10} | iteration={delta.get('iteration', '?')}\")\n",
    "    \n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(\"STREAM COMPLETE\")\n",
    "    print(f\"{'='*70}\\n\")\n",
    "\n",
    "\n",
    "# Uncomment to watch streaming\n",
    "# stream_reflection(\"How do LangGraph loops improve agent reliability?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d869168e",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ü§ù Part 5: Multi-Agent Debate Loop ‚Äî Collaborative Refinement\n",
    "\n",
    "**Final pattern**: What if we loop between **two different agents**?\n",
    "\n",
    "### The Challenge\n",
    "\n",
    "Agent A (Proposer): \"Here's my answer!\"  \n",
    "Agent B (Critic): \"Not good enough, improve X and Y\"  \n",
    "Agent A: \"How about now?\"  \n",
    "Agent B: \"Perfect! I agree!\" ‚úÖ\n",
    "\n",
    "**This is collaborative refinement through debate!**\n",
    "\n",
    "### Why This Matters\n",
    "\n",
    "Real-world scenarios:\n",
    "- **Code review**: Author ‚Üí Reviewer ‚Üí Author ‚Üí Approve\n",
    "- **Proposal refinement**: Drafter ‚Üí Stakeholder feedback ‚Üí Revision\n",
    "- **Adversarial validation**: Generator ‚Üí Discriminator (like GANs!)\n",
    "\n",
    "### What You'll Learn\n",
    "\n",
    "‚úÖ Multiple agents in one workflow  \n",
    "‚úÖ Consensus detection as exit condition  \n",
    "‚úÖ Agent-to-agent communication patterns  \n",
    "‚úÖ When collaboration beats solo work  \n",
    "\n",
    "**Let's build a debate system!** üëá"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96520157",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DebateState(BaseModel):\n",
    "    messages: Annotated[List[Union[HumanMessage, AIMessage]], add_messages] = Field(default_factory=list)\n",
    "    query: str = \"\"\n",
    "    proposal_text: str = \"\"  # Renamed from 'proposal' to avoid node name conflict\n",
    "    critique_text: str = \"\"  # Renamed from 'critique_response'\n",
    "    round: int = 0\n",
    "    max_rounds: int = 2\n",
    "    consensus: bool = False\n",
    "    \n",
    "    class Config:\n",
    "        arbitrary_types_allowed = True\n",
    "\n",
    "\n",
    "def proposer_node(state: DebateState):  # Renamed function for clarity\n",
    "    \"\"\"Agent A proposes or refines answer.\"\"\"\n",
    "    round_num = state.round + 1\n",
    "    \n",
    "    if round_num == 1:\n",
    "        prompt = f\"Propose an answer to: {state.query}\"\n",
    "    else:\n",
    "        prompt = f\"Refine your answer based on critique:\\n\\nQuery: {state.query}\\nPrevious: {state.proposal_text}\\nCritique: {state.critique_text}\\n\\nImproved answer:\"\n",
    "    \n",
    "    proposal = llm.invoke(prompt).content\n",
    "    print(f\"\\n[PROPOSER Round {round_num}]\")\n",
    "    print(f\"  {proposal[:120]}...\")\n",
    "    \n",
    "    return {\"proposal_text\": proposal, \"round\": round_num, \"messages\": [AIMessage(content=f\"Proposer: {proposal}\", name=\"proposer\")]}\n",
    "\n",
    "\n",
    "def critic_node(state: DebateState):  # Renamed function for clarity\n",
    "    \"\"\"Agent B critiques proposal.\"\"\"\n",
    "    prompt = f\"\"\"Critique this answer:\\n\\nQuery: {state.query}\\nProposal: {state.proposal_text}\\n\\nIf the answer is good enough, start your response with \"AGREE\".\n",
    "Otherwise, suggest specific improvements.\"\"\"\n",
    "    \n",
    "    critique = llm.invoke(prompt).content.strip()\n",
    "    # More robust consensus detection\n",
    "    consensus = critique.upper().startswith(\"AGREE\")\n",
    "    \n",
    "    print(f\"[CRITIC Round {state.round}]\")\n",
    "    if consensus:\n",
    "        print(f\"  ‚úÖ CONSENSUS reached!\")\n",
    "    else:\n",
    "        print(f\"  üí¨ Feedback: {critique[:100]}...\")\n",
    "    \n",
    "    return {\"critique_text\": critique, \"consensus\": consensus, \"messages\": [AIMessage(content=f\"Critic: {critique}\", name=\"critic\")]}\n",
    "\n",
    "\n",
    "def should_debate_continue(state: DebateState) -> str:\n",
    "    if state.consensus:\n",
    "        print(f\"  ‚Üí Consensus! Ending debate.\")\n",
    "        return \"end\"\n",
    "    elif state.round >= state.max_rounds:\n",
    "        print(f\"  ‚Üí Max rounds reached. Accepting proposal.\")\n",
    "        return \"end\"\n",
    "    else:\n",
    "        print(f\"  ‚Üí Continuing debate (round {state.round + 1})\")\n",
    "        return \"continue\"\n",
    "\n",
    "\n",
    "# Build debate loop\n",
    "debate_loop = StateGraph(DebateState)\n",
    "debate_loop.add_node(\"proposer\", proposer_node)  # Node name: \"proposer\" (no conflict!)\n",
    "debate_loop.add_node(\"critic\", critic_node)      # Node name: \"critic\" (no conflict!)\n",
    "\n",
    "debate_loop.set_entry_point(\"proposer\")\n",
    "debate_loop.add_edge(\"proposer\", \"critic\")\n",
    "\n",
    "# THE LOOP: debate continues until consensus or max rounds\n",
    "debate_loop.add_conditional_edges(\n",
    "    \"critic\",\n",
    "    should_debate_continue,\n",
    "    {\n",
    "        \"continue\": \"proposer\",  # üîÑ Loop back to proposer\n",
    "        \"end\": END\n",
    "    }\n",
    ")\n",
    "\n",
    "debate_agent = debate_loop.compile()\n",
    "print(\"‚úÖ Debate agent compiled\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bed9ea1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try it: Watch two agents debate\n",
    "query = \"What makes loops essential for production AI agents?\"\n",
    "result = debate_agent.invoke(DebateState(query=query))\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(f\"DEBATE COMPLETE after {result['round']} round(s)\")\n",
    "print(f\"{'='*70}\")\n",
    "print(f\"\\nFinal proposal:\\n{result['proposal_text']}\")\n",
    "print(f\"\\nFinal critique:\\n{result['critique_text']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ed3bdc2",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### ‚úÖ Part 5 Complete: Multi-Agent Loops\n",
    "\n",
    "**What You Just Built:**\n",
    "\n",
    "```mermaid\n",
    "graph LR\n",
    "    A[proposer: draft] --> B[critic: review]\n",
    "    B -->|disagree| A\n",
    "    B -->|agree| C[END]\n",
    "```\n",
    "\n",
    "### üîë Key Pattern: Agent Ping-Pong\n",
    "\n",
    "**Different from Parts 1-3**: Instead of ONE agent improving itself, TWO agents work together!\n",
    "\n",
    "```python\n",
    "# Part 2: Single agent self-critiques\n",
    "generate ‚Üí critique (same LLM) ‚Üí generate\n",
    "\n",
    "# Part 5: Two agents collaborate  \n",
    "proposer ‚Üí critic (different perspective) ‚Üí proposer\n",
    "```\n",
    "\n",
    "### üí° Exit Condition: Consensus Detection\n",
    "\n",
    "```python\n",
    "def critic_node(state):\n",
    "    critique = llm.invoke(\"Review this...\")\n",
    "    consensus = critique.upper().startswith(\"AGREE\")  # Keyword detection\n",
    "    return {\"consensus\": consensus, ...}\n",
    "\n",
    "def should_debate_continue(state):\n",
    "    if state.consensus:\n",
    "        return \"end\"  # ‚úÖ Both agree!\n",
    "    elif state.round >= max_rounds:\n",
    "        return \"end\"  # ‚ö†Ô∏è Time's up, accept proposal\n",
    "    else:\n",
    "        return \"continue\"  # üîÑ Keep debating\n",
    "```\n",
    "\n",
    "### üéØ When to Use Multi-Agent Loops\n",
    "\n",
    "‚úÖ **Excellent for**:\n",
    "- **Code review workflows**: Author ‚Üî Reviewer\n",
    "- **Proposal refinement**: Drafter ‚Üî Stakeholder\n",
    "- **Adversarial testing**: Generator ‚Üî Validator\n",
    "- **Roleplay scenarios**: Different perspectives improve output\n",
    "- **Expert panel**: Multiple specialized agents discuss\n",
    "\n",
    "‚ùå **Overkill for**:\n",
    "- Simple tasks (single agent sufficient)\n",
    "- High-latency scenarios (2√ó LLM calls per round)\n",
    "- When consensus isn't needed\n",
    "\n",
    "### üß† Advanced Patterns\n",
    "\n",
    "**What we built**: 2 agents, simple consensus\n",
    "\n",
    "**Production patterns**:\n",
    "- **3+ agents**: Panel of experts vote\n",
    "- **Weighted consensus**: Senior agent has veto power\n",
    "- **Hierarchical**: Manager ‚Üí Team ‚Üí Manager approval\n",
    "- **Adversarial**: Red team vs Blue team\n",
    "\n",
    "### üÜö Compare All Patterns\n",
    "\n",
    "| Part | Agents | Loop Target | Exit |\n",
    "|------|--------|-------------|------|\n",
    "| 1 | 1 agent | Same action 3√ó | Counter |\n",
    "| 2 | 1 agent | Self-improve | Score ‚â• 80 |\n",
    "| 3 | 1 agent | Different searches | Plan done |\n",
    "| 5 | 2 agents | Debate rounds | Consensus |\n",
    "\n",
    "**The power**: Mix and match these patterns! üé®\n",
    "\n",
    "---\n",
    "\n",
    "**Final step**: Let's wrap up everything you've learned! üëá"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1d5c4e6",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# \udf93 Workshop Complete: You're Now a Loop Master!\n",
    "\n",
    "Congratulations! You've built 5 different loop patterns from scratch. Let's solidify what you've learned.\n",
    "\n",
    "---\n",
    "\n",
    "## üìö Quick Reference: Your Loop Toolkit\n",
    "\n",
    "### The 5 Patterns You Mastered\n",
    "\n",
    "| Pattern | When to Use | Exit Strategy | Complexity |\n",
    "|---------|-------------|---------------|------------|\n",
    "| **üîÅ Fixed Iteration** | You know exactly how many rounds needed | `iteration >= N` | ‚≠ê Beginner |\n",
    "| **üìä Quality-Driven** | Loop until output meets standards | `score >= threshold` + max | ‚≠ê‚≠ê Intermediate |\n",
    "| **üîç Plan-Execution** | Execute list of different actions | Plan complete + early exit | ‚≠ê‚≠ê Intermediate |\n",
    "| **üé¨ Streaming/Persistent** | Long-running, resumable workflows | Any of above + checkpointing | ‚≠ê‚≠ê‚≠ê Advanced |\n",
    "| **ü§ù Multi-Agent** | Collaborative refinement needed | Consensus + max rounds | ‚≠ê‚≠ê‚≠ê Advanced |\n",
    "\n",
    "---\n",
    "\n",
    "## üéØ Decision Tree: Which Loop Should I Use?\n",
    "\n",
    "```\n",
    "Do you know the exact number of iterations needed?\n",
    "‚îú‚îÄ YES ‚Üí Fixed Iteration Loop (Part 1)\n",
    "‚îî‚îÄ NO ‚Üí Continue...\n",
    "    \n",
    "    Are you executing different actions each loop?\n",
    "    ‚îú‚îÄ YES ‚Üí Plan-Execution Loop (Part 3)\n",
    "    ‚îî‚îÄ NO ‚Üí Continue...\n",
    "        \n",
    "        Is quality measurable with a score?\n",
    "        ‚îú‚îÄ YES ‚Üí Quality-Driven Loop (Part 2)\n",
    "        ‚îî‚îÄ NO ‚Üí Continue...\n",
    "            \n",
    "            Do you need multiple perspectives?\n",
    "            ‚îú‚îÄ YES ‚Üí Multi-Agent Loop (Part 5)\n",
    "            ‚îî‚îÄ NO ‚Üí Maybe you don't need a loop! ü§î\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## ‚ö° The Golden Rules of Loop Design\n",
    "\n",
    "### ‚úÖ Always Do This\n",
    "\n",
    "1. **Include `max_iterations`** - NEVER ship without a safety limit!\n",
    "   ```python\n",
    "   max_iterations: int = 5  # Prevent infinite loops\n",
    "   ```\n",
    "\n",
    "2. **Track iterations in state** - Essential for debugging\n",
    "   ```python\n",
    "   iteration: int = 0  # Always increment this\n",
    "   ```\n",
    "\n",
    "3. **Log progress** - Help users (and yourself) understand what's happening\n",
    "   ```python\n",
    "   print(f\"[Iteration {iteration}] Score: {score}/100\")\n",
    "   ```\n",
    "\n",
    "4. **Have TWO exit conditions** - Quality goal + safety limit\n",
    "   ```python\n",
    "   if score >= 80:      # ‚úÖ Goal achieved\n",
    "       return \"done\"\n",
    "   elif iteration >= 5: # ‚ö†Ô∏è Safety limit\n",
    "       return \"done\"\n",
    "   ```\n",
    "\n",
    "### ‚ö†Ô∏è Common Pitfalls to Avoid\n",
    "\n",
    "| Mistake | Consequence | Solution |\n",
    "|---------|-------------|----------|\n",
    "| No `max_iterations` | Infinite loop üî• | Always set a limit! |\n",
    "| Too strict quality check | Always hits max iterations | Use scoring (60-100), not binary |\n",
    "| Too lenient quality check | Exits too early, poor results | Tune threshold with real data |\n",
    "| Not tracking cost | $$$ explosion | Monitor LLM call count |\n",
    "| Forgetting state evolution | Loops don't improve | Carry feedback between iterations |\n",
    "\n",
    "---\n",
    "\n",
    "## üîß Production Patterns: Combining Loops\n",
    "\n",
    "### Pattern 1: Quality Loop with Retry Logic\n",
    "```python\n",
    "# Outer loop: Quality-driven refinement\n",
    "# Inner loop: Retry each LLM call with exponential backoff\n",
    "\n",
    "generate (with retry) ‚Üí critique ‚Üí refine (with retry) ‚Üí repeat\n",
    "```\n",
    "\n",
    "### Pattern 2: Multi-Agent + Streaming\n",
    "```python\n",
    "# Watch debate in real-time\n",
    "for update in debate_agent.stream(state):\n",
    "    print(f\"Round {update['round']}: {update['proposal_text'][:50]}...\")\n",
    "```\n",
    "\n",
    "### Pattern 3: Research + Validation (Nested Loops)\n",
    "```python\n",
    "# Outer: Validate research quality\n",
    "# Inner: Execute search plan\n",
    "\n",
    "validate ‚Üí [insufficient? ‚Üí replan ‚Üí search (loop) ‚Üí synthesize] ‚Üí repeat\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## üöÄ Next Steps: Level Up Your Skills\n",
    "\n",
    "### üéØ Immediate Practice (Do This Today!)\n",
    "\n",
    "1. **Modify Part 2**: Change scoring to use YOUR quality criteria\n",
    "2. **Extend Part 3**: Add a 4th search to the plan\n",
    "3. **Combine Parts 2+4**: Add streaming to the quality loop\n",
    "\n",
    "### üìà Intermediate Projects (This Week)\n",
    "\n",
    "1. **Code Review Agent**: \n",
    "   - Part 2 (quality) + Part 5 (author ‚Üî reviewer)\n",
    "   \n",
    "2. **Research Assistant**:\n",
    "   - Part 3 (multi-search) + Part 2 (validate answer quality)\n",
    "   \n",
    "3. **Content Generator**:\n",
    "   - Part 1 (generate N drafts) ‚Üí Part 2 (pick best and refine)\n",
    "\n",
    "### üèÜ Advanced Challenges (When Ready)\n",
    "\n",
    "1. **Nested Loops**: Combine Part 2 inside Part 3\n",
    "2. **Parallel Loops**: Run multiple Part 1 loops simultaneously\n",
    "3. **HITL Loops**: Add `interrupt()` for human approval\n",
    "4. **Adaptive Thresholds**: Learn optimal `score_threshold` over time\n",
    "\n",
    "---\n",
    "\n",
    "## üìñ Key Takeaway\n",
    "\n",
    "### Before This Workshop:\n",
    "```python\n",
    "# One-shot agent (brittle!)\n",
    "user_question ‚Üí llm.invoke() ‚Üí answer\n",
    "```\n",
    "\n",
    "### After This Workshop:\n",
    "```python\n",
    "# Self-improving agent (resilient!)\n",
    "user_question ‚Üí [generate ‚Üí evaluate ‚Üí refine] √ó N ‚Üí quality_answer\n",
    "```\n",
    "\n",
    "**You've transformed brittle one-shot agents into resilient, self-improving systems!** üéâ\n",
    "\n",
    "---\n",
    "\n",
    "## üéì Certification: You Are Now\n",
    "\n",
    "‚úÖ Able to build loops that prevent infinite cycles  \n",
    "‚úÖ Skilled in quality-driven iteration  \n",
    "‚úÖ Confident with plan-execution patterns  \n",
    "‚úÖ Ready to combine loops for production systems  \n",
    "‚úÖ Aware of cost/quality tradeoffs  \n",
    "\n",
    "**Welcome to the world of production-ready AI agents!** üöÄ\n",
    "\n",
    "---\n",
    "\n",
    "## üìö Further Learning\n",
    "\n",
    "- **LangGraph Docs**: [langgraph.langchain.com](https://langchain-ai.github.io/langgraph/)\n",
    "- **Advanced Patterns**: See `Workshop_agent_v4_advanced.ipynb` for nested loops\n",
    "- **Community**: Share your loop patterns with the community!\n",
    "\n",
    "---\n",
    "\n",
    "**Final thought**: The difference between a demo and a production agent is often just one thing: **loops**. You now have that superpower! üí™\n",
    "\n",
    "**Thank you for attending this workshop!** \ude4f"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
