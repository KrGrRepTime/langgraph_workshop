{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eb139160",
   "metadata": {},
   "source": [
    "# LangGraph Agent v2 — Search + Process\n",
    "\n",
    "Adds web search and synthesis (no enrichment step).\n",
    "\n",
    "Quick guide:\n",
    "- State: messages, search_results, optimized_query\n",
    "- Nodes: analyze → search → process → END\n",
    "- Observe prints: [ANALYZE], [SEARCH], [PROCESS]\n",
    "- Run the last cell to see a clean, single execution trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e0616ed7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from typing import List, Optional, Union, Literal\n",
    "from dotenv import load_dotenv\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "from langgraph.graph import StateGraph, END\n",
    "\n",
    "from langchain_core.messages import HumanMessage, SystemMessage, AIMessage\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "from langchain_community.utilities import GoogleSearchAPIWrapper\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "99a8caeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SearchResult(BaseModel):\n",
    "    id: int\n",
    "    title: str\n",
    "    snippet: str\n",
    "    link: str\n",
    "    relevance_score: Optional[float] = None\n",
    "    full_content: Optional[str] = None\n",
    "\n",
    "class AgentState(BaseModel):\n",
    "    messages: List[Union[HumanMessage, AIMessage, SystemMessage]] = Field(description=\"The chat history\")\n",
    "    search_results: List[SearchResult] = Field(default_factory=list, description=\"The results from the web search\")\n",
    "    optimized_query: Optional[str] = Field(default=None, description=\"The LLM-optimized search query\")\n",
    "    \n",
    "    class Config:\n",
    "        arbitrary_types_allowed = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "06efa8ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatGoogleGenerativeAI(model=\"gemini-2.0-flash\", temperature=0.7)\n",
    "search_engine = GoogleSearchAPIWrapper(k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1cdf7914",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_query(state: AgentState):\n",
    "    print(\"[ANALYZE] Optimizing user query…\")\n",
    "    user_query = next((m.content for m in reversed(state.messages) if isinstance(m, HumanMessage)), \"\")\n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", \"You optimize search queries. Return ONLY the optimized query.\"),\n",
    "        (\"human\", \"Optimize: {q}\")])\n",
    "    q = llm.invoke(prompt.format_messages(q=user_query)).content.strip().replace('\\\"','')\n",
    "    return {\"optimized_query\": q}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2cdbed53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_search(state: AgentState):\n",
    "    print(\"[SEARCH] Running web search…\")\n",
    "    query = state.optimized_query or next((m.content for m in reversed(state.messages) if isinstance(m, HumanMessage)), \"\")\n",
    "    try:\n",
    "        raw = search_engine.results(query, num_results=5)\n",
    "    except Exception:\n",
    "        raw = [{\"title\":\"Search unavailable\",\"snippet\":f\"Could not search: {query}\",\"link\":\"https://example.com\"}]\n",
    "    results = [SearchResult(id=i+1,title=r.get('title','No title'),snippet=r.get('snippet',r.get('description','No content')),link=r.get('link',r.get('url','No link'))) for i,r in enumerate(raw)]\n",
    "    return {\"search_results\": results}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "51c73195",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_results(state: AgentState):\n",
    "    print(\"[PROCESS] Synthesizing final answer…\")\n",
    "    user_query = next((m.content for m in state.messages if isinstance(m, HumanMessage)), \"Unknown query\")\n",
    "    if state.search_results:\n",
    "        blocks = []\n",
    "        for r in state.search_results:\n",
    "            blocks.append(f\"Result {r.id} | {r.title}\\n{r.snippet}\\nSource: {r.link}\")\n",
    "        results_block = \"\\n\".join(blocks)\n",
    "    else:\n",
    "        results_block = \"No search results available.\"\n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", \"Use the search results to answer precisely with sources.\"),\n",
    "        (\"human\", \"Query: {q}\\n\\nResults:\\n{res}\")])\n",
    "    ans = llm.invoke(prompt.format_messages(q=user_query, res=results_block)).content.strip()\n",
    "    return {\"messages\": [AIMessage(content=ans)]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1955f045",
   "metadata": {},
   "outputs": [],
   "source": [
    "def route_to_search(state: AgentState) -> Literal['search']:\n",
    "    return 'search'\n",
    "def is_done(state: AgentState) -> Literal['end']:\n",
    "    return 'end'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67b0de71",
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow_v2 = StateGraph(AgentState)\n",
    "workflow_v2.add_node('analyze', analyze_query)\n",
    "workflow_v2.add_node('search', perform_search)\n",
    "workflow_v2.add_node('process', process_results)\n",
    "\n",
    "agent_v2 = workflow_v2.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09cf1865",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==== Conversation ====\n",
      "AI: Based on the search results, here are some of the teams that participated in the 2025 NBA Playoffs:\n",
      "\n",
      "*   **Eastern Conference:** Cavaliers, Heat, Pacers, Bucks, Knicks, Pistons (Source: Result 3)\n",
      "*   **Western Conference:** Oklahoma City Thunder, Memphis Grizzlies, Houston Rockets, Golden State Warriors (Source: Result 4)\n",
      "*   **Play-in Tournament:** Warriors, Grizzlies, Magic, and Heat advanced from the Play-In Tournament (Source: Result 1)\n"
     ]
    }
   ],
   "source": [
    "# Test v2\n",
    "query = 'Who were in 2025 NBA playoffs?'\n",
    "state = AgentState(messages=[HumanMessage(content=query)])\n",
    "final_state = agent_v2.invoke(state)\n",
    "\n",
    "print('==== Execution Trace ====')\n",
    "print('(Watch for: [ANALYZE] → [SEARCH] → [PROCESS])')\n",
    "print('\\n==== Conversation ====')\n",
    "for m in final_state['messages']:\n",
    "    if isinstance(m, HumanMessage):\n",
    "        print(f'Human: {m.content}')\n",
    "    elif isinstance(m, AIMessage):\n",
    "        print(f'AI: {m.content}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
